Document: Artificial_Intelligence
Section: INTELLIGENCE?
Tokens: 1204
--------------------------------------------------------------------------------

## INTELLIGENCE?

Early expectations that many new applications would be found for home robots have
not materialized.

Robot vacuum cleaners are restricted to localized flat areas, while real
homes have lots of single steps, and often staircases; there has been very little research
on robot mobility inside real homes.

Hardware platforms remain challenging to build,
and there are few applications that people want enough to buy .

Perceptual algorithms Over the next fifteen years,
coincident advances
in mechanical and AI
technologies promise to
increase the safe and
reliable use and utility of
home robots in a typical
North American city.

25for functions such as image labeling, and 3D object recognition, while common at AI
conferences, are still only a few years into development as products.

Home robots Despite the slow growth to date of robots in the home, there are signs that this will
change in the next fifteen years.

Corporations such as Amazon Robotics and Uber
are developing large economies of scale using various aggregation technologies.

Also:
System in Module (SiM), with a lot of System on Chip (SoC) subsystems, are
now being pushed out the door by phone-chip makers (Qualcomm’s SnapDragon,
Samsung’s Artik, etc.).

These are better than supercomputers of less than ten years
ago with eight or more sixty-four-bit cores, and specialized silicon for cryptography ,
camera drivers, additional DSPs, and hard silicon for certain perceptual algorithms.

This means that low cost devices will be able to support much more onboard AI than
we have been able to consider over the last fifteen years.

Cloud (“someone else’s computer”) is going to enable more rapid release of new
software on home robots, and more sharing of data sets gathered in many different
homes, which will in turn feed cloud-based machine learning, and then power
improvements to already deployed robots.

The great advances in speech understanding and image labeling enabled by deep
learning will enhance robots’ interactions with people in their homes.

Low cost 3D sensors, driven by gaming platforms, have fueled work on 3D
perception algorithms by thousands of researchers worldwide, which will speed the
development and adoption of home and service robots.

In the past three years, low cost and safe robot arms have been introduced to
hundreds of research labs around the world, sparking a new class of research on
manipulation that will eventually be applicable in the home, perhaps around 2025.

More than half a dozen startups around the world are developing AI-based robots for
the home, for now concentrating mainly on social interaction.

New ethics and privacy
issues may surface as a result.

HEALTHCARE
For AI technologies, healthcare has long been viewed as a promising domain.

AI-based applications could improve health outcomes and quality of life for
millions of people in the coming years—but only if they gain the trust of doctors,
nurses, and patients, and if policy , regulatory , and commercial obstacles are removed.

Prime applications include clinical decision support, patient monitoring and
coaching, automated devices to assist in surgery or patient care, and management
of healthcare systems.

Recent successes, such as mining social media to infer
possible health risks, machine learning to predict patients at risk, and robotics
to support surgery , have expanded a sense of possibility for AI in healthcare.

Improvements in methods for interacting with medical professionals and patients
will be a critical challenge.

As in other domains, data is a key enabler.

There has been an immense forward
leap in collecting useful data from personal monitoring devices and mobile apps, from
electronic health records (EHR) in clinical settings and, to a lesser extent, from robots
designed to assist with medical procedures and hospital operations.

But using this
data to enable more finely-grained diagnostics and treatments for both individual
patients and patient populations has proved difficult.

Research and deployment have
been slowed by outdated regulations and incentive structures.

Poor human-computer
interaction methods and the inherent difficulties and risks of implementing
technologies in such a large and complex system have slowed realization of AI’s Special purpose robots
will deliver packages,
clean offices, and enhance
security, but technical
constraints and high
costs will continue to limit
commercial opportunities
for the foreseeable future.

26promise in healthcare.61 The reduction or removal of these obstacles, combined with
innovations still on the horizon, have the potential to significantly improve health
outcomes and quality of life for millions of people in the coming years.

The clinical setting
For decades, the vision of an AI-powered clinician’s assistant has been a near cliché.

Although there have been successful pilots of AI-related technology in healthcare,62
the current healthcare delivery system unfortunately remains structurally ill-suited to
absorb and deploy rapid advances.

Incentives provided by the Affordable Care Act
have accelerated the penetration of electronic health records (EHRs) into clinical
practice, but implementation has been poor, eroding clinicians’ confidence in their
usefulness.

A small group of companies control the EHR market, and user interfaces
are widely considered substandard, including annoying pop-ups that physicians
routinely dismiss.

The promise of new analytics using data from EHRs, including AI,
remains largely unrealized due to these and other regulatory and structural barriers.

Looking ahead to the next fifteen years, AI advances, if coupled with sufficient data
and well-targeted systems, promise to change the cognitive tasks assigned to human
clinicians.

Physicians now routinely solicit verbal descriptions of symptoms from
presenting patients and, in their heads, correlate patterns against the clinical
presentation of known diseases.

With automated assistance, the physician could
instead supervise this process, applying her or his experience and intuition to guide the
input process and to evaluate the output of the machine intelligence.