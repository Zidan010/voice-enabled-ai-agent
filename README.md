# Voice-Enabled Agentic RAG

A modular, local Retrieval-Augmented Generation (RAG) pipeline for multi-domain document Q&A, featuring PDF cleaning, adaptive markdown chunking, FAISS vector indexing, multi-agent retrieval, and both text and voice CLI interfaces.

---

## ğŸ“ Project Description

This project enables advanced question answering over multiple expert domains (AI, Cybersecurity, Digital Health, Human Development, Renewable Energy Jobs) using a local RAG pipeline. It processes PDFs into cleaned markdown, chunks them into embedding-ready passages, builds FAISS vector indices per agent, and serves queries via a multi-agent router. You can interact via a text CLI or a voice CLI (Deepgram-powered).

**Key Features:**
- PDF â†’ cleaned markdown â†’ chunked passages â†’ FAISS vector store
- Multi-agent RAG runtime with agent registry
- Text CLI and Deepgram-based voice CLI
- Modular pipeline: cleaning, chunking, indexing, retrieval
- Extensible to new domains and function agents (weather, finance, etc.)

---

## ğŸ“‚ Project Structure

```
voice-enabled-ai-agent/
â”œâ”€ .env                      # API keys and config
â”œâ”€ README.md                 # This file
â”œâ”€ requirements.txt          # Python dependencies
â”œâ”€ clean_pdfs.py             # PDF cleaning pipeline
â”œâ”€ chunking.py               # Markdown chunking utilities
â”œâ”€ create_faiss_store.py     # Embedding + FAISS index creation
â”œâ”€ langchain_groq_rag.py     # RAG runtime and agent router
â”œâ”€ function_agents.py        # Live/function agents (weather, finance)
â”œâ”€ cli_chat.py               # Text CLI interface
â”œâ”€ voice_cli.py              # Voice CLI (Deepgram STT/TTS)
â”œâ”€ cleaned_texts/            # Cleaned markdown outputs
â”œâ”€ chunks/                   # Chunk outputs, stats, per-chunk files
â”‚   â”œâ”€ chunks.json           # All chunks (JSON)
â”‚   â”œâ”€ chunks.jsonl          # All chunks (JSONL)
â”‚   â”œâ”€ chunks.csv            # All chunks (CSV)
â”‚   â”œâ”€ chunking_statistics.json
â”‚   â””â”€ chunks_txt/           # Individual chunk text files
â”œâ”€ extracted_pdfs/           # Source PDFs
â”œâ”€ vector_store/             # FAISS indices and agent_registry.json
â”‚   â””â”€ agents/               # Per-agent FAISS index folders
â””â”€ voice_history/            # Generated TTS audio files
```

---

## ğŸ›  Prerequisites

- Python **3.10+**
- [Install dependencies](#installation--setup) via `requirements.txt`
- API keys:
  - `GROQ_API_KEY` (LLM, required)
  - `DEEPGRAM_API_KEY` (voice CLI, required for TTS/STT)
  - `TAVILY_API_KEY` (optional, for live function agents)
  - `VECTOR_STORE_DIR` (optional, override vector store path)

---

## âš™ï¸ Installation & Setup

### 1. Clone the repo
```bash
git clone <your-repo-url>
cd voice-enabled-ai-agent
```

### 2. Create and activate a virtual environment
```bash
python -m venv _env
# Windows:
_env\Scripts\activate
# macOS/Linux:
source _env/bin/activate
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

### 4. Configure API keys
Create a `.env` file at project root:
```ini
GROQ_API_KEY=sk-xxxxxxxx
DEEPGRAM_API_KEY=dg-xxxxxxxx
TAVILY_API_KEY=tv-xxxxxxxx   
```

---

## ğŸ“„ Data Preparation

### 1. Place PDFs
Copy your source PDFs into `extracted_pdfs/`. Example files:
- Artificial_Intelligence.pdf
- Cybersecurity.pdf
- Digital_Health.pdf
- Human_Development.pdf
- Renewable_Energy_Jobs.pdf

### 2. Clean PDFs â†’ Markdown
Run the PDF cleaning pipeline:
```bash
python clean_pdfs.py
```
- Outputs cleaned markdown files to `cleaned_texts/`
- Auto-detects document type and applies custom cleaning heuristics

### 3. Chunk Markdown
Chunk cleaned markdown into embedding-ready passages:
```bash
python chunking.py
```
- Outputs: `chunks/chunks.json`, `chunks.jsonl`, `chunks.csv`, `chunks_txt/`, `chunking_statistics.json`
- Chunk sizes/config can be adjusted in `MarkdownChunker.default_config()` in [chunking.py](chunking.py)

### 4. Build FAISS Indices
Generate embeddings and build FAISS indices per agent:
```bash
python create_faiss_store.py
```
- Outputs: `vector_store/agents/` (FAISS indices), `vector_store/agent_registry.json`
- Embedding model and batch size configurable in [create_faiss_store.py](create_faiss_store.py)

---

## ğŸš€ End-to-End Running Guide

### 1. Prepare Environment
- Activate your virtualenv
- Ensure `.env` is set with required API keys

### 2. Data Pipeline
- Place PDFs in `extracted_pdfs/`
- Run `clean_pdfs.py` â†’ check `cleaned_texts/`
- Run `chunking.py` â†’ check `chunks/` and `chunking_statistics.json`
- Run `create_faiss_store.py` â†’ check `vector_store/` and `agent_registry.json`

### 3. Start Text CLI
```bash
python cli_chat.py
```
- Interact with the multi-agent RAG system via terminal
- Supports `/help`, `/agents`, `/history`, `/stats`, `/exit` commands

### 4. Start Voice CLI (requires Deepgram API key)
```bash
python voice_cli.py
```
- Speak or provide audio files for Q&A
- Responses are converted to audio and saved in `voice_history/`

---

## ğŸ§  RAG Runtime & Agents

- **UnifiedAgentSystem** in [langchain_groq_rag.py](langchain_groq_rag.py) loads `vector_store/agent_registry.json` and serves `.query(user_query)`
- **AgentRetriever** utilities in [create_faiss_store.py](create_faiss_store.py) for retrieval inspection
- **Function agents** (weather, finance) in [function_agents.py](function_agents.py)

---

## ğŸ—‚ References & Outputs

- Cleaned markdown: [cleaned_texts/Artificial_Intelligence.md](cleaned_texts/Artificial_Intelligence.md)
- Chunks: [chunks/chunks.json](chunks/chunks.json), [chunks/chunks_txt/](chunks/chunks_txt/)
- Vector registry: [vector_store/agent_registry.json](vector_store/agent_registry.json)
- Voice history: [voice_history/](voice_history/)

---

## ğŸ Troubleshooting

- **Missing API keys:** Scripts will error if required keys are absentâ€”set them in `.env` or your environment.
- **Chunking:** Falls back to char-estimation if `tiktoken` is not installed.
- **FAISS:** On Windows, install `faiss-cpu` or platform-specific wheel; GPU variants need GPU-compatible packages.
- **Embeddings:** Change embedding model / batch size in `create_faiss_store.py` to reduce memory use.

---

## ğŸ’¡ Extending & Customizing

- Add new PDFs to `extracted_pdfs/` and rerun the pipeline
- Add new agent definitions in [create_faiss_store.py](create_faiss_store.py)
- Modify chunking logic in [chunking.py](chunking.py)
- Add new function agents in [function_agents.py](function_agents.py)

---

