{
  "agent_id": "Artificial_Intelligence",
  "agent_name": "AI & Machine Learning Expert",
  "agent_description": "Expert in artificial intelligence, machine learning, deep learning, neural networks, computer vision, NLP, robotics, and AI applications across various domains including transportation, healthcare, education, and employment.",
  "source_document": "Artificial_Intelligence.pdf",
  "embedding_model": 768,
  "embedding_dimension": 768,
  "total_vectors": 22,
  "chunks": [
    {
      "vector_id": 0,
      "chunk_id": "artificial_intelligence_chunk_000",
      "content": "## Artificial Intelligence\n\n---",
      "section_path": [
        "INTELLIGENCE?"
      ],
      "metadata": {
        "chunk_index": 0,
        "char_count": 31,
        "token_estimate": 5,
        "word_count": 4,
        "has_header": true,
        "header_text": "Artificial Intelligence",
        "header_level": 2,
        "parent_sections": [],
        "contains_list": false,
        "contains_numbered_list": false,
        "contains_quote": false,
        "contains_code": false,
        "embedding_ready": true,
        "total_chunks_in_doc": 22,
        "prev_chunk_id": null,
        "next_chunk_id": "artificial_intelligence_chunk_001"
      }
    },
    {
      "vector_id": 1,
      "chunk_id": "artificial_intelligence_chunk_001",
      "content": "## INTELLIGENCE?\n\nThis section describes how researchers and practitioners define “ Artificial Intelligence,” and\nthe areas of AI research and application that are currently thriving.\n\nIt proffers definitions of\nwhat AI is and is not, and describes some of the currently “hot” areas of AI Research.\n\nThis\nsection lays the groundwork for Section II, which elaborates on AI’s impacts and future in\neight domains and Section III, which describes issues related to AI design and public policy\nand makes recommendations for encouraging AI innovation while protecting democratic values.\n\nDEFINING AI\nCuriously , the lack of a precise, universally accepted definition of AI probably\nhas helped the field to grow, blossom, and advance at an ever-accelerating pace.\n\nPractitioners, researchers, and developers of AI are instead guided by a rough\nsense of direction and an imperative to “get on with it.” Still, a definition remains\nimportant and Nils J.\n\nNilsson has provided a useful one:\n“ Artificial intelligence is that activity devoted to making machines intelligent, and\nintelligence is that quality that enables an entity to function appropriately and with\nforesight in its environment.”3\nFrom this perspective, characterizing AI depends on the credit one is willing to\ngive synthesized software and hardware for functioning “appropriately” and with\n“foresight.” A simple electronic calculator performs calculations much faster than\nthe human brain, and almost never makes a mistake.4 Is a calculator intelligent?\n\nLike Nilsson, the Study Panel takes a broad view that intelligence lies on a multidimensional spectrum.\n\nAccording to this view, the difference between an arithmetic\ncalculator and a human brain is not one of kind, but of scale, speed, degree of\nautonomy , and generality .\n\nThe same factors can be used to evaluate every other\ninstance of intelligence—speech recognition software, animal brains, cruise-control\nsystems in cars, Go-playing programs, thermostats—and to place them at some\nappropriate location in the spectrum.\n\nAlthough our broad interpretation places the calculator within the intelligence\nspectrum, such simple devices bear little resemblance to today’s AI.\n\nThe frontier of\nAI has moved far ahead and functions of the calculator are only one among the\nmillions that today’s smartphones can perform.\n\nAI developers now work on improving,\ngeneralizing, and scaling up the intelligence currently found on smartphones.\n\nIn fact, the field of AI is a continual endeavor to push forward the frontier of\nmachine intelligence.\n\nIronically , AI suffers the perennial fate of losing claim to its\nacquisitions, which eventually and inevitably get pulled inside the frontier, a repeating\npattern known as the “ AI effect” or the “odd paradox”—AI brings a new technology\ninto the common fold, people become accustomed to this technology , it stops being\nconsidered AI, and newer technology emerges.5 The same pattern will continue in the\nfuture.\n\nAI does not “deliver” a life-changing product as a bolt from the blue.\n\nRather,\nAI technologies continue to get better in a continual, incremental way .\n\nNils J.\n\nNilsson, The Quest for Artificial Intelligence: A History of Ideas and Achievements (Cambridge,\nUK: Cambridge University Press, 2010).\n\ncommons/b/b6/SHARP_ELSIMATE_EL-W221.jpg .\n\nPamela McCorduck, Machines Who Think: A Personal Inquiry into the History and Prospects of\nArtificial Intelligence , 2nd ed.\n\n(Natick, MA: A.\n\nK.\n\nPeters, Ltd., 2004; San Francisco: W .\n\nH.\n\nFreeman,\n1979), Citations are to the Peters edition.An accurate and\nsophisticated picture of\nAI—one that competes with\nits popular portrayal—is\nhampered by the difficulty\nof pinning down a precise\ndefinition of artificial\nintelligence.\n\n13The human measure\nNotably , the characterization of intelligence as a spectrum grants no special status\nto the human brain.\n\nBut to date human intelligence has no match in the biological\nand artificial worlds for sheer versatility , with the abilities “to reason, achieve\ngoals, understand and generate language, perceive and respond to sensory inputs,\nprove mathematical theorems, play challenging games, synthesize and summarize\ninformation, create art and music, and even write histories.”6\nThis makes human intelligence a natural choice for benchmarking the progress\nof AI.\n\nIt may even be proposed, as a rule of thumb, that any activity computers\nare able to perform and people once performed should be counted as an instance\nof intelligence.\n\nBut matching any human ability is only a sufficient condition, not a\nnecessary one.\n\nThere are already many systems that exceed human intelligence, at\nleast in speed, such as scheduling the daily arrivals and departures of thousands of\nflights in an airport.\n\nAI’s long quest—and eventual success—to beat human players at the game of\nchess offered a high-profile instance for comparing human to machine intelligence.\n\nChess has fascinated people for centuries.\n\nWhen the possibility of building computers\nbecame imminent, Alan Turing, who many consider the father of computer science,\n“mentioned the idea of computers showing intelligence with chess as a paradigm.”7\nWithout access to powerful computers, “Turing played a game in which he simulated\nthe computer, taking about half an hour per move.”\nBut it was only after a long line of improvements in the sixties and seventies—\ncontributed by groups at Carnegie Mellon, Stanford, MIT , The Institute for\nTheoretical and Experimental Physics at Moscow, and Northwestern University—\nthat chess-playing programs started gaining proficiency .\n\nThe final push came\nthrough a long-running project at IBM, which culminated with the Deep Blue\nprogram beating Garry Kasparov, then the world chess champion, by a score of\n3.5-2.5 in 1997.",
      "section_path": [
        "INTELLIGENCE?"
      ],
      "metadata": {
        "chunk_index": 1,
        "char_count": 5767,
        "token_estimate": 1193,
        "word_count": 879,
        "has_header": true,
        "header_text": "INTELLIGENCE?",
        "header_level": 2,
        "parent_sections": [],
        "contains_list": false,
        "contains_numbered_list": false,
        "contains_quote": false,
        "contains_code": false,
        "embedding_ready": true,
        "total_chunks_in_doc": 22,
        "prev_chunk_id": "artificial_intelligence_chunk_000",
        "next_chunk_id": "artificial_intelligence_chunk_002"
      }
    },
    {
      "vector_id": 2,
      "chunk_id": "artificial_intelligence_chunk_002",
      "content": "## INTELLIGENCE?\n\nThe final push came\nthrough a long-running project at IBM, which culminated with the Deep Blue\nprogram beating Garry Kasparov, then the world chess champion, by a score of\n3.5-2.5 in 1997.\n\nCuriously , no sooner had AI caught up with its elusive target than\nDeep Blue was portrayed as a collection of “brute force methods” that wasn’t “real\nintelligence.”8 In fact, IBM’s subsequent publication about Deep Blue, which gives\nextensive details about its search and evaluation procedures, doesn’t mention the\nword “intelligent” even once!9 Was Deep Blue intelligent or not?\n\nOnce again, the\nfrontier had moved.\n\nAn operational definition\nAI can also be defined by what AI researchers do.\n\nThis report views AI\nprimarily as a branch of computer science that studies the properties of\nintelligence by synthesizing intelligence.10 Though the advent of AI has depended\non the rapid progress of hardware computing resources, the focus here on\nsoftware reflects a trend in the AI community .\n\nMore recently , though, progress in\nbuilding hardware tailored for neural-network-based computing11 has created a Nilsson, The Quest for Artificial Intelligence .\n\nNilsson, The Quest for Artificial Intelligence , 89.\n\nMcCorduck, Machines Who Think , 433.\n\nMurray Campbell, A.\n\nJoseph Hoane Jr., and Feng-hsiung Hsu, “Deep Blue,” Artificial\nIntelligence 134, nos.\n\nand: 57–83.\n\nHerbert A.\n\nSimon, “ Artificial Intelligence: An Empirical Science,” Artificial Intelligence 77, no.:95–127.\n\nPaul Merolla John V .\n\nArthur, Rodrigo Alvarez-Icaza, Andrew S.\n\nCassidy , Jun Sawada, Filipp\nAkopyan, Bryan L.\n\nJackson, Nabil Imam, Chen Guo, Yutaka Nakamura, Bernard Brezzo, Ivan Vo,\nSteven K.\n\nEsser, Rathinakumar Appuswamy , Brian Taba, Arnon Amir, Myron D.\n\nFlickner, William\nP .\n\nRisk, Rajit Manohar, and Dharmendra S.\n\nModha, “ A Million Spiking-Neuron Integrated\nCircuit with a Scalable Communication Network and Interface,” paulmerolla.com/merolla_main_som.pdf .Intelligence lies on a\nmulti-dimensional\nspectrum.\n\nAccording to\nthis view, the difference\nbetween an arithmetic\ncalculator and a human\nbrain is not one of kind,\nbut of scale, speed,\ndegree of autonomy, and\ngenerality.\n\n14tighter coupling between hardware and software in advancing AI.\n\n“Intelligence” remains a complex phenomenon whose varied aspects have attracted\nthe attention of several different fields of study , including psychology , economics,\nneuroscience, biology , engineering, statistics, and linguistics.\n\nNaturally , the field of AI has\nbenefited from the progress made by all of these allied fields.\n\nFor example, the artificial\nneural network, which has been at the heart of several AI-based solutions12 was\noriginally inspired by thoughts about the flow of information in biological neurons.14\nAI RESEARCH TRENDS\nUntil the turn of the millennium, AI’s appeal lay largely in its promise to deliver, but\nin the last fifteen years, much of that promise has been redeemed.15 AI technologies\nalready pervade our lives.\n\nAs they becomes a central force in society , the field is\nshifting from simply building systems that are intelligent to building intelligent systems\nthat are human-aware and trustworthy .\n\nSeveral factors have fueled the AI revolution.\n\nForemost among them is the\nmaturing of machine learning, supported in part by cloud computing resources\nand wide-spread, web-based data gathering.\n\nMachine learning has been propelled\ndramatically forward by “deep learning,” a form of adaptive artificial neural\nnetworks trained using a method called backpropagation.16 This leap in the\nperformance of information processing algorithms has been accompanied by\nsignificant progress in hardware technology for basic operations such as sensing,\nperception, and object recognition.\n\nNew platforms and markets for data-driven\nproducts, and the economic incentives to find new products and markets, have also\ncontributed to the advent of AI-driven technology .\n\nAll these trends drive the “hot” areas of research described below.\n\nThis compilation\nis meant simply to reflect the areas that, by one metric or another, currently receive\ngreater attention than others.\n\nThey are not necessarily more important or valuable\nthan other ones.\n\nIndeed, some of the currently “hot” areas were less popular in past\nyears, and it is likely that other areas will similarly re-emerge in the future.\n\nLarge-scale machine learning\nMany of the basic problems in machine learning (such as supervised and\nunsupervised learning) are well-understood.\n\nA major focus of current efforts is to\nscale existing algorithms to work with extremely large data sets.\n\nFor example, whereas\ntraditional methods could afford to make several passes over the data set, modern\nones are designed to make only a single pass; in some cases, only sublinear methods\n(those that only look at a fraction of the data) can be admitted.\n\nDeep learning\nThe ability to successfully train convolutional neural networks has most benefited the\nfield of computer vision, with applications such as object recognition, video Gerald Tesauro, “Practical Issues in Temporal Difference Learning,” Machine Learning , no.: 257–77.\n\nDavid Silver, Aja Huang, Chris J.",
      "section_path": [
        "INTELLIGENCE?"
      ],
      "metadata": {
        "chunk_index": 2,
        "char_count": 5180,
        "token_estimate": 1133,
        "word_count": 779,
        "has_header": true,
        "header_text": "INTELLIGENCE?",
        "header_level": 2,
        "parent_sections": [],
        "contains_list": false,
        "contains_numbered_list": false,
        "contains_quote": false,
        "contains_code": false,
        "embedding_ready": true,
        "total_chunks_in_doc": 22,
        "prev_chunk_id": "artificial_intelligence_chunk_001",
        "next_chunk_id": "artificial_intelligence_chunk_003"
      }
    },
    {
      "vector_id": 3,
      "chunk_id": "artificial_intelligence_chunk_003",
      "content": "## INTELLIGENCE?\n\nDavid Silver, Aja Huang, Chris J.\n\nMaddison, Arthur Guez, Laurent Sifre, George van den\nDriessche, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, Sander\nDieleman, Dominik Grewe, John Nham, Nal Kalchbrenner, Ilya Sutskever, Timothy Lillicrap,\nMadeleine Leach, Koray Kavukcuoglu, Thore Graepel, and Demis Hassabis, “Mastering the game\nof Go with deep neural networks and tree search,” Nature: 484–489.\n\nW .\n\nMcCulloch and W .\n\nPitts, W ., “ A logical calculus of the ideas immanent in nervous activity ,”\nBulletin of Mathematical Biophysics ,: 115–133.\n\nAppendix I offers a short history of AI, including a description of some of the traditionally\ncore areas of research, which have shifted over the past six decades.\n\nBackpropagation is an abbreviation for “backward propagation of errors,” a common method\nof training artificial neural networks used in conjunction with an optimization method such as\ngradient descent.\n\nThe method calculates the gradient of a loss function with respect to all the\nweights in the network.Human intelligence has\nno match in the biological\nand artificial worlds for\nsheer versatility, with\nthe abilities “to reason,\nachieve goals, understand\nand generate language...\n\ncreate art and music, and\neven write histories.”\n15labeling, activity recognition, and several variants thereof.\n\nDeep learning is also making\nsignificant inroads into other areas of perception, such as audio, speech, and natural\nlanguage processing.\n\nReinforcement learning\nWhereas traditional machine learning has mostly focused on pattern mining,\nreinforcement learning shifts the focus to decision making, and is a technology that\nwill help AI to advance more deeply into the realm of learning about and executing\nactions in the real world.\n\nIt has existed for several decades as a framework for\nexperience-driven sequential decision-making, but the methods have not found great\nsuccess in practice, mainly owing to issues of representation and scaling.\n\nHowever,\nthe advent of deep learning has provided reinforcement learning with a “shot in the\narm.” The recent success of AlphaGo, a computer program developed by Google\nDeepmind that beat the human Go champion in a five-game match, was due in large\npart to reinforcement learning.\n\nAlphaGo was trained by initializing an automated\nagent with a human expert database, but was subsequently refined by playing a large\nnumber of games against itself and applying reinforcement learning.\n\nRobotics\nRobotic navigation, at least in static environments, is largely solved.\n\nCurrent efforts\nconsider how to train a robot to interact with the world around it in generalizable\nand predictable ways.\n\nA natural requirement that arises in interactive environments\nis manipulation , another topic of current interest.\n\nThe deep learning revolution is\nonly beginning to influence robotics, in large part because it is far more difficult to\nacquire the large labeled data sets that have driven other learning-based areas of AI.\n\nReinforcement learning (see above), which obviates the requirement of labeled data,\nmay help bridge this gap but requires systems to be able to safely explore a policy\nspace without committing errors that harm the system itself or others.\n\nAdvances in\nreliable machine perception, including computer vision, force, and tactile perception,\nmuch of which will be driven by machine learning, will continue to be key enablers to\nadvancing the capabilities of robotics.\n\nComputer vision\nComputer vision is currently the most prominent form of machine perception.\n\nIt has\nbeen the sub-area of AI most transformed by the rise of deep learning.\n\nUntil just a\nfew years ago, support vector machines were the method of choice for most visual\nclassification tasks.\n\nBut the confluence of large-scale computing, especially on GPUs,\nthe availability of large datasets, especially via the internet, and refinements of neural\nnetwork algorithms has led to dramatic improvements in performance on benchmark\ntasks (e.g., classification on ImageNet17).\n\nFor the first time, computers are able to\nperform some (narrowly defined) visual classification tasks better than people.\n\nMuch\ncurrent research is focused on automatic image and video captioning.\n\nNatural Language Processing\nOften coupled with automatic speech recognition, Natural Language Processing is\nanother very active area of machine perception.\n\nIt is quickly becoming a commodity\nfor mainstream languages with large data sets.\n\nGoogle announced that 20% of\ncurrent mobile queries are done by voice,18 and recent demonstrations have proven\nthe possibility of real-time translation.\n\nResearch is now shifting towards developing\nrefined and capable systems that are able to interact with people through dialog, not\njust react to stylized requests.\n\nImageNet, Stanford Vision Lab, Stanford University , Princeton University , 2016, accessed\nAugust 1, 2016,  Greg Sterling, “Google says 20% of mobile queries are voice searches,” Search Engine Land ,\nMay 18, 2016, queries-voice-queries-249917 .AI technologies already\npervade our lives.\n\nAs\nthey become a central\nforce in society, the\nfield is shifting from\nsimply building systems\nthat are intelligent to\nbuilding intelligent\nsystems that are\nhuman-aware and\ntrustworthy.\n\n16Collaborative systems\nResearch on collaborative systems investigates models and algorithms to help\ndevelop autonomous systems that can work collaboratively with other systems and\nwith humans.\n\nThis research relies on developing formal models of collaboration,\nand studies the capabilities needed for systems to become effective partners.\n\nThere\nis growing interest in applications that can utilize the complementary strengths of\nhumans and machines—for humans to help AI systems to overcome their limitations,\nand for agents to augment human abilities and activities.",
      "section_path": [
        "INTELLIGENCE?"
      ],
      "metadata": {
        "chunk_index": 3,
        "char_count": 5854,
        "token_estimate": 1206,
        "word_count": 865,
        "has_header": true,
        "header_text": "INTELLIGENCE?",
        "header_level": 2,
        "parent_sections": [],
        "contains_list": false,
        "contains_numbered_list": false,
        "contains_quote": false,
        "contains_code": false,
        "embedding_ready": true,
        "total_chunks_in_doc": 22,
        "prev_chunk_id": "artificial_intelligence_chunk_002",
        "next_chunk_id": "artificial_intelligence_chunk_004"
      }
    },
    {
      "vector_id": 4,
      "chunk_id": "artificial_intelligence_chunk_004",
      "content": "## INTELLIGENCE?\n\nThere\nis growing interest in applications that can utilize the complementary strengths of\nhumans and machines—for humans to help AI systems to overcome their limitations,\nand for agents to augment human abilities and activities.\n\nCrowdsourcing and human computation\nSince human abilities are superior to automated methods for accomplishing many\ntasks, research on crowdsourcing and human computation investigates methods to\naugment computer systems by utilizing human intelligence to solve problems that\ncomputers alone cannot solve well.\n\nIntroduced only about fifteen years ago, this\nresearch now has an established presence in AI.\n\nThe best-known example of\ncrowdsourcing is Wikipedia, a knowledge repository that is maintained and updated\nby netizens and that far exceeds traditionally-compiled information sources, such\nas encyclopedias and dictionaries, in scale and depth.\n\nCrowdsourcing focuses on\ndevising innovative ways to harness human intelligence.\n\nCitizen science platforms\nenergize volunteers to solve scientific problems, while paid crowdsourcing platforms\nsuch as Amazon Mechanical Turk provide automated access to human intelligence on\ndemand.\n\nWork in this area has facilitated advances in other subfields of AI, including\ncomputer vision and NLP , by enabling large amounts of labeled training data and/or\nhuman interaction data to be collected in a short amount of time.\n\nCurrent research\nefforts explore ideal divisions of tasks between humans and machines based on their\ndiffering capabilities and costs.\n\nAlgorithmic game theory and computational social choice\nNew attention is being drawn to the economic and social computing dimensions of\nAI, including incentive structures.\n\nDistributed AI and multi-agent systems have been\nstudied since the early 1980s, gained prominence starting in the late 1990s, and were\naccelerated by the internet.\n\nA natural requirement is that systems handle potentially\nmisaligned incentives, including self-interested human participants or firms, as well\nas automated AI-based agents representing them.\n\nTopics receiving attention include\ncomputational mechanism design (an economic theory of incentive design, seeking\nincentive-compatible systems where inputs are truthfully reported), computational\nsocial choice (a theory for how to aggregate rank orders on alternatives), incentive\naligned information elicitation (prediction markets, scoring rules, peer prediction) and\nalgorithmic game theory (the equilibria of markets, network games, and parlor games\nsuch as Poker—a game where significant advances have been made in recent years\nthrough abstraction techniques and no-regret learning).\n\nInternet of Things (IoT)\nA growing body of research is devoted to the idea that a wide array of devices can\nbe interconnected to collect and share their sensory information.\n\nSuch devices can\ninclude appliances, vehicles, buildings, cameras, and other things.\n\nWhile it’s a matter\nof technology and wireless networking to connect the devices, AI can process and\nuse the resulting huge amounts of data for intelligent and useful purposes.\n\nCurrently ,\nthese devices use a bewildering array of incompatible communication protocols.\n\nAI\ncould help tame this Tower of Babel.\n\nNeuromorphic Computing\nTraditional computers implement the von Neumann model of computing, which\nseparates the modules for input/output, instruction-processing, and memory .\n\nWith\nthe success of deep neural networks on a wide array of tasks, manufacturers are Natural Language\nProcessing is a very\nactive area of machine\nperception.\n\nResearch\nis now shifting towards\ndeveloping systems that\nare able to interact with\npeople through dialog,\nnot just react to stylized\nrequests.\n\n17actively pursuing alternative models of computing—especially those that are inspired\nby what is known about biological neural networks—with the aim of improving the\nhardware efficiency and robustness of computing systems.\n\nAt the moment, such\n“neuromorphic” computers have not yet clearly demonstrated big wins, and are just\nbeginning to become commercially viable.\n\nBut it is possible that they will become\ncommonplace (even if only as additions to their von Neumann cousins) in the\nnear future.\n\nDeep neural networks have already created a splash in the application\nlandscape.\n\nA larger wave may hit when these networks can be trained and executed\non dedicated neuromorphic hardware, as opposed to simulated on standard von\nNeumann architectures, as they are today .\n\nOverall trends and the future of AI research\nThe resounding success of the data-driven paradigm has displaced the traditional\nparadigms of AI.\n\nProcedures such as theorem proving and logic-based knowledge\nrepresentation and reasoning are receiving reduced attention, in part because of the\nongoing challenge of connecting with real-world groundings.\n\nPlanning, which was a\nmainstay of AI research in the seventies and eighties, has also received less attention\nof late due in part to its strong reliance on modeling assumptions that are hard\nto satisfy in realistic applications.\n\nModel-based approaches—such as physics-based\napproaches to vision and traditional control and mapping in robotics—have by and\nlarge given way to data-driven approaches that close the loop with sensing the results\nof actions in the task at hand.\n\nBayesian reasoning and graphical models, which were\nvery popular even quite recently , also appear to be going out of favor, having been\ndrowned by the deluge of data and the remarkable success of deep learning.\n\nOver the next fifteen years, the Study Panel expects an increasing focus on\ndeveloping systems that are human-aware, meaning that they specifically model,\nand are specifically designed for, the characteristics of the people with whom they\nare meant to interact.\n\nThere is a lot of interest in trying to find new, creative ways\nto develop interactive and scalable ways to teach robots.\n\nAlso, IoT-type systems—\ndevices and the cloud—are becoming increasingly popular, as is thinking about\nsocial and economic dimensions of AI.\n\nIn the coming years, new perception/object\nrecognition capabilities and robotic platforms that are human-safe will grow, as will\ndata-driven products and their markets.",
      "section_path": [
        "INTELLIGENCE?"
      ],
      "metadata": {
        "chunk_index": 4,
        "char_count": 6226,
        "token_estimate": 1202,
        "word_count": 909,
        "has_header": true,
        "header_text": "INTELLIGENCE?",
        "header_level": 2,
        "parent_sections": [],
        "contains_list": false,
        "contains_numbered_list": false,
        "contains_quote": false,
        "contains_code": false,
        "embedding_ready": true,
        "total_chunks_in_doc": 22,
        "prev_chunk_id": "artificial_intelligence_chunk_003",
        "next_chunk_id": "artificial_intelligence_chunk_005"
      }
    },
    {
      "vector_id": 5,
      "chunk_id": "artificial_intelligence_chunk_005",
      "content": "## INTELLIGENCE?\n\nIn the coming years, new perception/object\nrecognition capabilities and robotic platforms that are human-safe will grow, as will\ndata-driven products and their markets.\n\nThe Study Panel also expects a reemergence of some of the traditional forms of\nAI as practitioners come to realize the inevitable limitations of purely end-to-end deep\nlearning approaches.\n\nWe encourage young researchers not to reinvent the wheel,\nbut rather to maintain an awareness of the significant progress in many areas of\nAI during the first fifty years of the field, and in related fields such as control theory ,\ncognitive science, and psychology .A growing body of research\nis devoted to the idea that\na wide array of devices\ncan be interconnected\nto collect and share their\nsensory information.\n\nSuch devices can include\nappliances, vehicles,\nbuildings, cameras, and\nother things.\n\n# Though different instances of AI research and practice share common technologies, such\n\nas machine learning, they also vary considerably in different sectors of the economy and\nsociety.\n\nWe call these sectors “domains,” and in this section describe the different states\nof AI research and implementation, as well as impacts and distinct challenges, in eight of\nthem: transportation; home/service robotics; healthcare; education; low-resource communities;\npublic safety and security; employment and workplace; and entertainment.\n\nBased on these\nanalyses, we also predict trends in a typical North American city over the next fifteen years.\n\nContrary to AI’s typical depiction in popular culture, we seek to offer a balanced overview\nof the ways in which AI is already beginning to transform everyday life, and how those\ntransformations are likely to grow by the year 2030.\n\nTRANSPORTATION\nTransportation is likely to be one of the first domains in which the general public\nwill be asked to trust the reliability and safety of an AI system for a critical task.\n\nAutonomous transportation will soon be commonplace and, as most people’s first\nexperience with physically embodied AI systems, will strongly influence the public’s\nperception of AI.\n\nOnce the physical hardware is made sufficiently safe and robust, its\nintroduction to daily life may happen so suddenly as to surprise the public, which will\nrequire time to adjust.\n\nAs cars will become better drivers than people, city-dwellers\nwill own fewer cars, live further from work, and spend time differently , leading to an\nentirely new urban organization.\n\nFurther, in the typical North American city in 2030,\nchanges won’t be limited to cars and trucks, but are likely to include flying vehicles\nand personal robots, and will raise social, ethical and policy issues.\n\nA few key technologies have already catalyzed the widespread adoption of AI\nin transportation.\n\nCompared to 2000, the scale and diversity of data about personal\nand population-level transportation available today—enabled by the adoption of\nsmartphones and decreased costs and improved accuracies for variety of sensors—is\nastounding.\n\nWithout the availability of this data and connectivity , applications such as\nreal-time sensing and prediction of traffic, route calculations, peer-to-peer ridesharing\nand self-driving cars would not be possible.\n\nSmarter cars\nGPS was introduced to personal vehicles in with in-car navigation devices and\nhas since become a fundamental part of the transportation infrastructure.19 GPS\nassists drivers while providing large-scale information to technology companies and\ncities about transportation patterns.\n\nWidespread adoption of smartphones with GPS\ntechnology further increased connectivity and the amount of location data shared by\nindividuals.\n\nCurrent vehicles are also equipped with a wide range of sensing capabilities.\n\nAn average automobile in the US is predicted to have seventy sensors including\ngyroscopes, accelerometers, ambient light sensors, and moisture sensors.20 Sensors\nare not new to vehicles.\n\nAutomobiles built before had sensors for the\ninternal state of the vehicle such as its speed, acceleration, and wheel position.21 Mark Sullivan, “ A brief history of GPS,” PCWorld , August 9, 2012, .\n\nWilliam J.\n\nFleming, “New Automotive Sensors - A Review,” IEEE Sensors Journal 8, no ,: 1900-1921.\n\nJean Jacques Meneu, ed., “ Automotive Sensors: Now and in the Future,” Arrow , September 24,\n2015, sensors-now-and-in-the-future .Autonomous\ntransportation will soon\nbe commonplace and,\nas most people’s first\nexperience with physically\nembodied AI systems,\nwill strongly influence the\npublic’s perception of AI.\n\n19They already had a number of functionalities that combined real-time sensing with\nperception and decision-making such as Anti-lock Braking Systems (ABS), airbag\ncontrol, Traction Control Systems (TCS), and Electronic Stability Control (ESC).22\nAutomated capabilities have been introduced into commercial cars gradually since as summarized in the following table.\n\nContext Automated Functionality Release Date\nParking Intelligent Parking Assist System Since Parking Summon Since Arterial & Highway Lane departure system Since in North America25\nArterial & Highway Adaptive cruise control Since in North America26\nHighway Blind spot monitoring Highway Lane changing These functionalities assist drivers or completely take over well-defined activities\nfor increased safety and comfort.\n\nCurrent cars can park themselves, perform adaptive\ncruise control on highways, steer themselves during stop-and-go traffic, and alert\ndrivers about objects in blind spots during lane changes.\n\nVision and radar technology\nwere leveraged to develop pre-collision systems that let cars autonomously brake\nwhen risk of a collision is detected.\n\nDeep learning also has been applied to improve\nautomobiles’ capacity to detect objects in the environment and recognize sound .29\nSelf-driving vehicles\nSince the 1930s, science fiction writers dreamed of a future with self-driving cars,\nand building them has been a challenge for the AI community since the 1960s.",
      "section_path": [
        "INTELLIGENCE?"
      ],
      "metadata": {
        "chunk_index": 5,
        "char_count": 6010,
        "token_estimate": 1200,
        "word_count": 887,
        "has_header": true,
        "header_text": "INTELLIGENCE?",
        "header_level": 2,
        "parent_sections": [],
        "contains_list": false,
        "contains_numbered_list": false,
        "contains_quote": false,
        "contains_code": false,
        "embedding_ready": true,
        "total_chunks_in_doc": 22,
        "prev_chunk_id": "artificial_intelligence_chunk_004",
        "next_chunk_id": "artificial_intelligence_chunk_006"
      }
    },
    {
      "vector_id": 6,
      "chunk_id": "artificial_intelligence_chunk_006",
      "content": "## INTELLIGENCE?\n\nDeep learning also has been applied to improve\nautomobiles’ capacity to detect objects in the environment and recognize sound .29\nSelf-driving vehicles\nSince the 1930s, science fiction writers dreamed of a future with self-driving cars,\nand building them has been a challenge for the AI community since the 1960s.\n\nBy\nthe 2000s, the dream of autonomous vehicles became a reality in the sea and sky , and\neven on Mars, but self-driving cars existed only as research prototypes in labs.\n\nDriving\nin a city was considered to be a problem too complex for automation due to factors\nlike pedestrians, heavy traffic, and the many unexpected events that can happen\noutside of the car’s control.\n\nAlthough the technological components required to Carl Liersch, “Vehicle Technology Timeline: From Automated to Driverless,” Robert Bosch\n(Australia) Pty.\n\nLtd., 2014, file/0009/246807/Carl_Liersch_Presentation.pdf .\n\n“Intelligent Parking Assist System,” Wikipedia , last modified July 26, 2016, accessed August 1,\n2016, .\n\nThe Tesla Motors Team, “Summon Your Tesla from Your Phone,” Tesla, January 10, 2016,\n2016, .\n\n“ Autonomous cruise control system,” Wikipedia , last modified July 30, 2016, accessed August 1,\n2016, .\n\n“Blind spot monitor,” Wikipedia , last modified April 20, 2016, .\n\nDana Hull, “Tesla Starts Rolling Out Autopilot Features,” Boomberg Technology , October 14,\n2015, software-upgrade-adds-automated-lane-changing-to-model-s .\n\nAaron Tilley , “New Qualcomm Chip Brings Deep Learning To Cars,” Forbes , January 5, 2016,\nnew-qualcomm-chip-brings-deep-learning-to-cars/#4cb4e9235357 .As cars will become better\ndrivers than people, citydwellers will own fewer\ncars, live further from\nwork, and spend time\ndifferently, leading to\nan entirely new urban\norganization.\n\n20make such autonomous driving possible were available in 2000—and indeed some\nautonomous car prototypes existed30 32—few predicted that mainstream companies\nwould be developing and deploying autonomous cars by 2015.\n\nDuring the first\nDefense Advanced Research Projects Agency (DARPA) “grand challenge” on\nautonomous driving in 2004, research teams failed to complete the challenge in a\nlimited desert setting.\n\nBut in eight short years, from 2004-2012, speedy and surprising progress occurred\nin both academia and industry .\n\nAdvances in sensing technology and machine learning\nfor perception tasks has sped progress and, as a result, Google’s autonomous vehicles\nand Tesla’s semi-autonomous cars are driving on city streets today .\n\nGoogle’s selfdriving cars, which have logged more than 1,500,000 miles (300,000 miles without an\naccident),33 are completely autonomous—no human input needed.\n\nTesla has widely\nreleased self-driving capability to existing cars with a software update.34 Their cars are\nsemi-autonomous, with human drivers expected to stay engaged and take over if they\ndetect a potential problem.\n\nIt is not yet clear whether this semi-autonomous approach\nis sustainable, since as people become more confident in the cars’ capabilities, they\nare likely to pay less attention to the road, and become less reliable when they are\nmost needed.\n\nThe first traffic fatality involving an autonomous car, which occurred in\nJune of 2016, brought this question into sharper focus.35\nIn the near future, sensing algorithms will achieve super-human performance for\ncapabilities required for driving.\n\nAutomated perception, including vision, is already\nnear or at human-level performance for well-defined tasks such as recognition and\ntracking.\n\nAdvances in perception will be followed by algorithmic improvements\nin higher level reasoning capabilities such as planning.\n\nA recent report predicts\nself-driving cars to be widely adopted by 2020.36 And the adoption of self-driving\ncapabilities won’t be limited to personal transportation.\n\nWe will see self-driving and\nremotely controlled delivery vehicles, flying vehicles, and trucks.\n\nPeer-to-peer\ntransportation services such as ridesharing are also likely to utilize self-driving vehicles.\n\nBeyond self-driving cars, advances in robotics will facilitate the creation and adoption\nof other types of autonomous vehicles, including robots and drones.\n\nIt is not yet clear how much better self-driving cars need to become to encourage\nbroad acceptance.\n\nThe collaboration required in semi-self-driving cars and its\nimplications for the cognitive load of human drivers is not well understood.\n\nBut\nif future self-driving cars are adopted with the predicted speed, and they exceed\nhuman-level performance in driving, other significant societal changes will follow.\n\nSelf-driving cars will eliminate one of the biggest causes of accidental death and\ninjury in United States, and lengthen people’s life expectancy .\n\nOn average, a “Navlab,” Wikipedia , last updated June 4, 2016, org/wiki/Navlab .\n\n“Navlab: The Carnegie Mellon University Navigation Laboratory ,” Carnegie Mellon\nUniversity , 2016, .\n\n“Google Self-Driving Car Project,” Google, com/selfdrivingcar/ .\n\nMolly McHugh, “Tesla’s Cars Now Drive Themselves, Kinda,” Wired ,\nOctober 14, 2015, air-update-live/ .\n\nMolly McHugh, “Tesla’s Cars Now Drive Themselves, Kinda,” Wired , October 14, 2015,\nYork Times , Last updated July 12, 2016, interactive/2016/07/01/business/inside-tesla-accident.html .",
      "section_path": [
        "INTELLIGENCE?"
      ],
      "metadata": {
        "chunk_index": 6,
        "char_count": 5297,
        "token_estimate": 1185,
        "word_count": 759,
        "has_header": true,
        "header_text": "INTELLIGENCE?",
        "header_level": 2,
        "parent_sections": [],
        "contains_list": false,
        "contains_numbered_list": false,
        "contains_quote": false,
        "contains_code": false,
        "embedding_ready": true,
        "total_chunks_in_doc": 22,
        "prev_chunk_id": "artificial_intelligence_chunk_005",
        "next_chunk_id": "artificial_intelligence_chunk_007"
      }
    },
    {
      "vector_id": 7,
      "chunk_id": "artificial_intelligence_chunk_007",
      "content": "## INTELLIGENCE?\n\nMolly McHugh, “Tesla’s Cars Now Drive Themselves, Kinda,” Wired , October 14, 2015,\nYork Times , Last updated July 12, 2016, interactive/2016/07/01/business/inside-tesla-accident.html .\n\nJohn Greenough, “10 million self-driving cars will be on the road by 2020,” Business Insider ,\nJune 15, 2016, driving-cars-will-be-on-the-road-by-2020-2015-5-6 .We will see self-driving and\nremotely controlled delivery\nvehicles, flying vehicles,\nand trucks.\n\nPeer-to-peer\ntransportation services\nsuch as ridesharing are\nalso likely to utilize selfdriving vehicles.\n\n21commuter in US spends twenty-five minutes driving each way .37 With self-driving car\ntechnology , people will have more time to work or entertain themselves during their\ncommutes.\n\nAnd the increased comfort and decreased cognitive load with self-driving\ncars and shared transportation may affect where people choose to live.\n\nThe reduced\nneed for parking may affect the way cities and public spaces are designed.\n\nSelf-driving\ncars may also serve to increase the freedom and mobility of different subgroups of\nthe population, including youth, elderly and disabled.\n\nSelf-driving cars and peer-to-peer transportation services may eliminate the need\nto own a vehicle.\n\nThe effect on total car use is hard to predict.\n\nTrips of empty vehicles\nand people’s increased willingness to travel may lead to more total miles driven.\n\nAlternatively , shared autonomous vehicles—people using cars as a service rather than\nowning their own—may reduce total miles, especially if combined with well-constructed\nincentives, such as tolls or discounts, to spread out travel demand, share trips, and\nreduce congestion.\n\nThe availability of shared transportation may displace the need\nfor public transportation—or public transportation may change form towards\npersonal rapid transit, already available in four cities,38 which uses small capacity\nvehicles to transport people on demand and point-to-point between many stations.39\nAs autonomous vehicles become more widespread, questions will arise over their\nsecurity , including how to ensure that technologies are safe and properly tested\nunder different road conditions prior to their release.\n\nAutonomous vehicles and the\nconnected transportation infrastructure will create a new venue for hackers to exploit\nvulnerabilities to attack.\n\nEthical questions are also involved in programming cars to\nact in situations in which human injury or death is inevitable, especially when there\nare split-second choices to be made about whom to put at risk.\n\nThe legal systems in\nmost states in the US do not have rules covering self-driving cars.\n\nAs of 2016, four\nstates in the US (Nevada, Florida, California, and Michigan), Ontario in Canada,\nthe United Kingdom, France, and Switzerland have passed rules for the testing\nof self-driving cars on public roads.\n\nEven these laws do not address issues about\nresponsibility and assignment of blame for an accident for self-driving and semi-selfdriving cars.40\nTransportation planning\nBy 2005, cities had started investing in the transportation infrastructure to develop\nsensing capabilities for vehicle and pedestrian traffic.41 The sensors currently used\ninclude inductive loops, video cameras, remote traffic microwave sensors, radars, and\nGPS.42 For example, in New York started using a combination of microwave\nsensors, a network of cameras, and pass readers to detect vehicle traffic in the city .43 Brian McKenzie and Melanie Rapino, “Commuting in the United States: 2009,” American\nCommunity Survey Reports , United States Census Bureau, September 2011, .\n\nMorgantown, West Virginia; Masdar City , UAE; London, England; and Suncheon, South\nKorea.\n\n“Personal rapid transit,” Wikipedia , Last modified July 18, 2016, .\n\nPatrick Lin, “The Ethics of Autonomous Cars,” The Atlantic , October 8, 2013, accessed\nAugust 1, 2016,\nautonomous-cars/280360/ .\n\nSteve Lohr, “Bringing Efficiency to the Infrastructure,” The New York Times , April 29,\n2009, environment/30smart.html .\n\n“Intelligent transportation system,” Wikipedia , last modified July 28, 2016, .\n\nAccess Science Editors, “ Active traffic management: adaptive traffic signal control,” Access Science ,\n2014, adaptive-traffic-signal-control/BR0106141 .Shared transportation\nmay displace the need for\npublic transportation—\nor public transportation\nmay change form towards\npersonal rapid transit\nthat uses small capacity\nvehicles to transport\npeople on demand.\n\n22Cities use AI methods to optimize services in several ways, such as bus and subway\nschedules, and tracking traffic conditions to dynamically adjust speed limits or apply\nsmart pricing on highways, bridges, and HOV lanes.44 46 Using sensors and cameras\nin the road network, they can also optimize traffic light timing for improving traffic\nflow and to help with automated enforcement.47 These dynamic strategies are aimed\nat better utilizing the limited resources in the transportation network, and are made\npossible by the availability of data and the widespread connectivity of individuals.\n\nBefore the 2000s, transportation planners were forced to rely on static pricing\nstrategies tied to particular days or times of day , to manage demand.\n\nAs dynamic\npricing strategies are adopted, this raises new issues concerning the fair distribution\nof public goods, since market conditions in high-demand situations may make\nservices unavailable to segments of the public.\n\nThe availability of large-scale data has also made transportation an ideal domain\nfor machine learning applications.",
      "section_path": [
        "INTELLIGENCE?"
      ],
      "metadata": {
        "chunk_index": 7,
        "char_count": 5549,
        "token_estimate": 1170,
        "word_count": 802,
        "has_header": true,
        "header_text": "INTELLIGENCE?",
        "header_level": 2,
        "parent_sections": [],
        "contains_list": false,
        "contains_numbered_list": false,
        "contains_quote": false,
        "contains_code": false,
        "embedding_ready": true,
        "total_chunks_in_doc": 22,
        "prev_chunk_id": "artificial_intelligence_chunk_006",
        "next_chunk_id": "artificial_intelligence_chunk_008"
      }
    },
    {
      "vector_id": 8,
      "chunk_id": "artificial_intelligence_chunk_008",
      "content": "## INTELLIGENCE?\n\nThe availability of large-scale data has also made transportation an ideal domain\nfor machine learning applications.\n\nSince 2006, applications such as Mapquest, Google\nMaps, and Bing Maps have been widely used by the public for routing trips, using public\ntransportation, receiving real-time information and predictions about traffic conditions, 50 and finding services around a location.51 Optimal search algorithms have been\napplied to the routing of vehicles and pedestrians to a given destination (i.e.,53 54).\n\nDespite these advances, the widespread application of sensing and optimization\ntechniques to city infrastructure has been slower than the application of these\ntechniques to individual vehicles or people.\n\nAlthough individual cities have\nimplemented sensing and optimization applications, as yet there is no standardization\nof the sensing infrastructure and AI techniques used.\n\nInfrastructure costs, differing\npriorities among cities, and the high coordination costs among the parties involved\nhave slowed adoption, as have public concerns over privacy related to sensing.\n\nStill, Kitae Jang, Koohong Chung, and Hwasoo Yeo, “ A Dynamic Pricing Strategy for High\nOccupancy Toll Lanes,” Transportation Research Part A: Policy and Practice: 69–80.\n\n“Seattle Variable Tolling Study ,” City of Seattle Department of Transportation, May 2009,\nStudy%20report%20revised%206.25.10.pdf .\n\nJames F .\n\nPeltz, “Dynamic Pricing Is Catching On in the Public and Private Sectors,”\nGovernment Technology , March 21, 2016, finance/Dynamic-Pricing-Is-Catching-On-in-the-Public-and-Private-Sectors.html .\n\nArthur G Sims and Kenneth W .\n\nDobinson.\n\n“The Sydney Coordinated Adaptive Traffic:\n130–137.\n\n“New York City Launches Nation’s Most Sophisticated Active Traffic Management System\nPowered by TransCore’s TransSuite Traffic Management Software and RFID Technology ,”\nBusiness Wire , September 27, 2009, home/20110927005530/en/York-City-Launches-Nation%E2%80%99s-Sophisticated-Active-Traffic .\n\nEric Horvitz, Johnson Apacible, Raman Sarin, and Lin Liao, “Prediction, Expectation, and\nSurprise: Methods, Designs, and Study of a Deployed Traffic Forecasting Service,” Proceedings of the\nTwenty-First Conference on Uncertainty and Artificial Intelligence (Arlington, Virginia: AUAI Press,\nJuly 2005), 275–283.\n\nTimothy Hunter, Ryan Herring, Pieter Abbeel, and Alexandre Bayen, “Path and Travel Time\nInference from GPS Probe Vehicle Data,” NIPS Analyzing Networks and Learning with Graphs , no.\n\nJohn Krumm and Eric Horvitz, “Predestination: Inferring Destinations from Partial\nTrajectories,” UbiComp 2006: Ubiquitous Computing, Proceedings of the 8th International Conference ,\nSeptember 2006,, 243–260.\n\nJill Duffy , “Get Organized: Using Location-Based Reminders,” PC Magazine , June 30, 2014,\nfor Real-time Route Planning,” IEEE Transactions on Aerospace and Electronic Systems , no.:\n869–878.\n\nMatt Duckham and Lars Kulik, “Simplest” Paths: Automated Route Selection for\nNavigation,” Spatial Information Theory .\n\nFoundations of Geographic Information Science,\nProceedings of the International Conference, COSIT 2003, September (Springer-Verlag\nBerlin Heidelberg, 2003), 169-185.Ethical questions arise\nwhen programming cars to\nact in situations in which\nhuman injury or death is\ninevitable, especially when\nthere are split-second\nchoices to be made about\nwhom to put at risk.\n\n23AI is likely to have an increasing impact on city infrastructure.\n\nAccurate predictive\nmodels of individuals’ movements, their preferences, and their goals are likely to\nemerge with the greater availability of data.\n\nThe ethical issues regarding such an\nemergence are discussed in Section III of this report.\n\nThe United States Department of Transportation released a call for proposals in asking medium-size cities to imagine smart city infrastructure for transportation.55\nThis initiative plans to award forty million dollars to a city to demonstrate how\ntechnology and data can be used to reimagine the movement of people as well as goods.\n\nOne vision is a network of connected vehicles that can reach a high level of safety\nin driving with car-to-car communication.56 If this vision becomes reality , we expect\nadvances in multi-agent coordination, collaboration, and planning will have a\nsignificant impact on future cars and play a role in making the transportation system\nmore reliable and efficient.\n\nRobots are also likely to take part in transportation by\ncarrying individuals and packages (c.f., Segway robot).\n\nFor transportation of goods,\ninterest in drones has increased, and Amazon is currently testing a delivery system using\nthem,57 although questions remain about the appropriate safety rules and regulations.\n\nThe increased sensing capabilities, adoption of drones, and the connected\ntransportation infrastructure will also raise concerns about the privacy of individuals\nand the safety of private data.\n\nIn coming years, these and related transportation issues\nwill need to be addressed either by preemptive action on the part of industry or within\nthe legal framework.\n\nAs noted in the Section III policy discussion, how well this is done\nwill affect the pace and scope of AI-related advances in the transportation sector.",
      "section_path": [
        "INTELLIGENCE?"
      ],
      "metadata": {
        "chunk_index": 8,
        "char_count": 5240,
        "token_estimate": 1128,
        "word_count": 731,
        "has_header": true,
        "header_text": "INTELLIGENCE?",
        "header_level": 2,
        "parent_sections": [],
        "contains_list": false,
        "contains_numbered_list": false,
        "contains_quote": false,
        "contains_code": false,
        "embedding_ready": true,
        "total_chunks_in_doc": 22,
        "prev_chunk_id": "artificial_intelligence_chunk_007",
        "next_chunk_id": "artificial_intelligence_chunk_009"
      }
    },
    {
      "vector_id": 9,
      "chunk_id": "artificial_intelligence_chunk_009",
      "content": "## INTELLIGENCE?\n\nAs noted in the Section III policy discussion, how well this is done\nwill affect the pace and scope of AI-related advances in the transportation sector.\n\nOn-demand transportation\nOn-demand transportation services such as Uber and Lyft have emerged as another\npivotal application of sensing, connectivity , and AI,58 with algorithms for matching\ndrivers to passengers by location and suitability (reputation modeling).59 Through dynamic pricing, these services ration access by willingness-to-pay , with\ndynamic pricing also encouraging an increase in the supply of drivers, and have\nbecome a popular method for transportation in cities.\n\nWith their rapid advance have\ncome multiple policy and legal issues, such as competition with existing taxi services\nand concerns about lack of regulation and safety .\n\nOn-demand transportation services\nseem likely to be a major force towards self-driving cars.\n\nCarpooling and ridesharing have long been seen as a promising approach to\ndecrease traffic congestion and better utilize personal transportation resources.\n\nServices such as Zimride and Nuride bring together people sharing similar routes for a\njoint trip.\n\nBut this approach to carpooling has failed to gain traction on a large scale.\n\n“U.S.\n\nDepartment of Transportation Launches Smart City Challenge to Create a City of\nthe Future,” Transportation.gov, U.S.\n\nDepartment of Transportation, December 7, 2015, accessed\nAugust 1, 2016,\nlaunches-smart-city-challenge-create-city-future .\n\nWill Knight, “Car-to-Car Communication: A simple wireless technology promises to\nmake driving much safer.,” MIT Technology Review , technologyreview.com/s/534981/car-to-car-communication/ .\n\n“ Amazon Prime Air,” Amazon, b?node=8037720011 .\n\nJared Meyer, “Uber and Lyft are changing the way Americans move about their country ,”\nNational Review , June 7, 2016, article/436263/uber-lyft-ride-sharing-services-sharing-economy-are-future .\n\nAlexander Howard, “How Digital Platforms Like LinkedIn, Uber And TaskRabbit Are\nChanging The On-Demand Economy ,” The Huffington Post , July 14, 2015, .\n\n“ Announcing UberPool,” Uber Newsroom, August 5, 2014, newsroom.uber.com/announcing-uberpool/ .Our Study Panel doesn’t\nexpect drones that can\nfly, swim, and drive, or\nflying quadcoptors to\nbecome a common means\nof transportation by (although prototypes exist\ntoday).\n\n24Interacting with people\nFor decades, people have imagined wildly different, futuristic-looking transportation\nvehicles.\n\nAlthough future cars will be smarter and drones will be available widely , it\nis unlikely that by we will have widely adopted transportation vehicles that look\nand function differently than the ones we have today .\n\nOur Study Panel doesn’t expect\ndrones that can fly , swim, and drive, or flying quadcoptors to become a common\nmeans of transportation in this time horizon (although prototypes exist today).\n\nWe do expect humans to become partners to self-driving cars and drones in their\ntraining, execution, and evaluation.\n\nThis partnering will happen both when humans\nare co-located with machines and also virtually .\n\nWe predict advances in algorithms to\nfacilitate machine learning from human input.\n\nWe also expect models and algorithms\nfor modeling of human attention, and to support communication and coordination\nbetween humans and machine.\n\nThis is an integral part of the development of\nfuture vehicles.\n\nHOME/SERVICE ROBOTS\nRobots have entered people’s homes in the past fifteen years.\n\nDisappointingly slow\ngrowth in the diversity of applications has occurred simultaneously with increasingly\nsophisticated AI deployed on existing applications.\n\nAI advances are often inspired by\nmechanical innovations, which in turn prompt new AI techniques to be introduced.\n\nOver the next fifteen years, coincident advances in mechanical and AI technologies\npromise to increase the safe and reliable use and utility of home robots in a typical\nNorth American city .\n\nSpecial purpose robots will deliver packages, clean offices,\nand enhance security , but technical constraints and the high costs of reliable\nmechanical devices will continue to limit commercial opportunities to narrowly\ndefined applications for the foreseeable future.\n\nAs with self-driving cars and other\nnew transportation machines, the difficulty of creating reliable, market-ready\nhardware is not to be underestimated.\n\nVacuum cleaners\nIn 2001, after many years of development, the Electrolux Trilobite, a vacuum\ncleaning robot, became the first commercial home robot.\n\nIt had a simple control\nsystem to do obstacle avoidance, and some navigation.\n\nA year later, iRobot introduced\nRoomba, which was a tenth the price of the Trilobite and, with only bytes of\nRAM, ran a behavior based controller.\n\nThe most intelligent thing it did was to avoid\nfalling down stairs.\n\nSince then, sixteen million Roombas have been deployed all over\nthe world and several other competing brands now exist.\n\nAs the processing power and RAM capacity of low cost embedded processors\nimproved from its dismal state in the year 2000, the AI capabilities of these robots\nalso improved dramatically .\n\nSimple navigation, self-charging, and actions for dealing\nwith full dust bins were added, followed by ability to deal with electrical cords and\nrug tassels, enabled by a combination of mechanical improvements and sensor\nbased perception.\n\nMore recently , the addition of full VSLAM (Visual Simultaneous\nLocation and Mapping)— an AI technology that had been around for twenty years—\nhas enabled the robots to build a complete 3D world model of a house as they clean,\nand become more efficient in their cleaning coverage.\n\nEarly expectations that many new applications would be found for home robots have\nnot materialized.",
      "section_path": [
        "INTELLIGENCE?"
      ],
      "metadata": {
        "chunk_index": 9,
        "char_count": 5753,
        "token_estimate": 1191,
        "word_count": 843,
        "has_header": true,
        "header_text": "INTELLIGENCE?",
        "header_level": 2,
        "parent_sections": [],
        "contains_list": false,
        "contains_numbered_list": false,
        "contains_quote": false,
        "contains_code": false,
        "embedding_ready": true,
        "total_chunks_in_doc": 22,
        "prev_chunk_id": "artificial_intelligence_chunk_008",
        "next_chunk_id": "artificial_intelligence_chunk_010"
      }
    },
    {
      "vector_id": 10,
      "chunk_id": "artificial_intelligence_chunk_010",
      "content": "## INTELLIGENCE?\n\nEarly expectations that many new applications would be found for home robots have\nnot materialized.\n\nRobot vacuum cleaners are restricted to localized flat areas, while real\nhomes have lots of single steps, and often staircases; there has been very little research\non robot mobility inside real homes.\n\nHardware platforms remain challenging to build,\nand there are few applications that people want enough to buy .\n\nPerceptual algorithms Over the next fifteen years,\ncoincident advances\nin mechanical and AI\ntechnologies promise to\nincrease the safe and\nreliable use and utility of\nhome robots in a typical\nNorth American city.\n\n25for functions such as image labeling, and 3D object recognition, while common at AI\nconferences, are still only a few years into development as products.\n\nHome robots Despite the slow growth to date of robots in the home, there are signs that this will\nchange in the next fifteen years.\n\nCorporations such as Amazon Robotics and Uber\nare developing large economies of scale using various aggregation technologies.\n\nAlso:\nSystem in Module (SiM), with a lot of System on Chip (SoC) subsystems, are\nnow being pushed out the door by phone-chip makers (Qualcomm’s SnapDragon,\nSamsung’s Artik, etc.).\n\nThese are better than supercomputers of less than ten years\nago with eight or more sixty-four-bit cores, and specialized silicon for cryptography ,\ncamera drivers, additional DSPs, and hard silicon for certain perceptual algorithms.\n\nThis means that low cost devices will be able to support much more onboard AI than\nwe have been able to consider over the last fifteen years.\n\nCloud (“someone else’s computer”) is going to enable more rapid release of new\nsoftware on home robots, and more sharing of data sets gathered in many different\nhomes, which will in turn feed cloud-based machine learning, and then power\nimprovements to already deployed robots.\n\nThe great advances in speech understanding and image labeling enabled by deep\nlearning will enhance robots’ interactions with people in their homes.\n\nLow cost 3D sensors, driven by gaming platforms, have fueled work on 3D\nperception algorithms by thousands of researchers worldwide, which will speed the\ndevelopment and adoption of home and service robots.\n\nIn the past three years, low cost and safe robot arms have been introduced to\nhundreds of research labs around the world, sparking a new class of research on\nmanipulation that will eventually be applicable in the home, perhaps around 2025.\n\nMore than half a dozen startups around the world are developing AI-based robots for\nthe home, for now concentrating mainly on social interaction.\n\nNew ethics and privacy\nissues may surface as a result.\n\nHEALTHCARE\nFor AI technologies, healthcare has long been viewed as a promising domain.\n\nAI-based applications could improve health outcomes and quality of life for\nmillions of people in the coming years—but only if they gain the trust of doctors,\nnurses, and patients, and if policy , regulatory , and commercial obstacles are removed.\n\nPrime applications include clinical decision support, patient monitoring and\ncoaching, automated devices to assist in surgery or patient care, and management\nof healthcare systems.\n\nRecent successes, such as mining social media to infer\npossible health risks, machine learning to predict patients at risk, and robotics\nto support surgery , have expanded a sense of possibility for AI in healthcare.\n\nImprovements in methods for interacting with medical professionals and patients\nwill be a critical challenge.\n\nAs in other domains, data is a key enabler.\n\nThere has been an immense forward\nleap in collecting useful data from personal monitoring devices and mobile apps, from\nelectronic health records (EHR) in clinical settings and, to a lesser extent, from robots\ndesigned to assist with medical procedures and hospital operations.\n\nBut using this\ndata to enable more finely-grained diagnostics and treatments for both individual\npatients and patient populations has proved difficult.\n\nResearch and deployment have\nbeen slowed by outdated regulations and incentive structures.\n\nPoor human-computer\ninteraction methods and the inherent difficulties and risks of implementing\ntechnologies in such a large and complex system have slowed realization of AI’s Special purpose robots\nwill deliver packages,\nclean offices, and enhance\nsecurity, but technical\nconstraints and high\ncosts will continue to limit\ncommercial opportunities\nfor the foreseeable future.\n\n26promise in healthcare.61 The reduction or removal of these obstacles, combined with\ninnovations still on the horizon, have the potential to significantly improve health\noutcomes and quality of life for millions of people in the coming years.\n\nThe clinical setting\nFor decades, the vision of an AI-powered clinician’s assistant has been a near cliché.\n\nAlthough there have been successful pilots of AI-related technology in healthcare,62\nthe current healthcare delivery system unfortunately remains structurally ill-suited to\nabsorb and deploy rapid advances.\n\nIncentives provided by the Affordable Care Act\nhave accelerated the penetration of electronic health records (EHRs) into clinical\npractice, but implementation has been poor, eroding clinicians’ confidence in their\nusefulness.\n\nA small group of companies control the EHR market, and user interfaces\nare widely considered substandard, including annoying pop-ups that physicians\nroutinely dismiss.\n\nThe promise of new analytics using data from EHRs, including AI,\nremains largely unrealized due to these and other regulatory and structural barriers.\n\nLooking ahead to the next fifteen years, AI advances, if coupled with sufficient data\nand well-targeted systems, promise to change the cognitive tasks assigned to human\nclinicians.\n\nPhysicians now routinely solicit verbal descriptions of symptoms from\npresenting patients and, in their heads, correlate patterns against the clinical\npresentation of known diseases.\n\nWith automated assistance, the physician could\ninstead supervise this process, applying her or his experience and intuition to guide the\ninput process and to evaluate the output of the machine intelligence.",
      "section_path": [
        "INTELLIGENCE?"
      ],
      "metadata": {
        "chunk_index": 10,
        "char_count": 6179,
        "token_estimate": 1204,
        "word_count": 930,
        "has_header": true,
        "header_text": "INTELLIGENCE?",
        "header_level": 2,
        "parent_sections": [],
        "contains_list": false,
        "contains_numbered_list": false,
        "contains_quote": false,
        "contains_code": false,
        "embedding_ready": true,
        "total_chunks_in_doc": 22,
        "prev_chunk_id": "artificial_intelligence_chunk_009",
        "next_chunk_id": "artificial_intelligence_chunk_011"
      }
    },
    {
      "vector_id": 11,
      "chunk_id": "artificial_intelligence_chunk_011",
      "content": "## INTELLIGENCE?\n\nWith automated assistance, the physician could\ninstead supervise this process, applying her or his experience and intuition to guide the\ninput process and to evaluate the output of the machine intelligence.\n\nThe literal\n“hands-on” experience of the physician will remain critical.\n\nA significant challenge is to\noptimally integrate the human dimensions of care with automated reasoning processes.\n\nTo achieve future advances, clinicians must be involved and engaged at the outset to\nensure that systems are well-engineered and trusted.\n\nAlready , a new generation of more\ntech savvy physicians routinely utilize specialized apps on mobile devices.\n\nAt the same\ntime, workloads on primary care clinicians have increased to the point that they are\ngrateful for help from any quarter.\n\nThus, the opportunity to exploit new learning methods,\nto create structured patterns of inference by mining the scientific literature automatically ,\nand to create true cognitive assistants by supporting free-form dialogue, has never\nbeen greater.\n\nProvided these advances are not stymied by regulatory , legal, and social\nbarriers, immense improvements to the value of healthcare are within our grasp.\n\nHealthcare analytics\nAt the population level, AI’s ability to mine outcomes from millions of patient clinical\nrecords promises to enable finer-grained, more personalized diagnosis and treatment.\n\nAutomated discovery of genotype-phenotype connections will also become possible\nas full, once-in-a-lifetime genome sequencing becomes routine for each patient.\n\nA related (and perhaps earlier) capability will be to find “patients like mine” as a way\nto inform treatment decisions based on analysis of a similar cohort.\n\nTraditional and\nnon-traditional healthcare data, augmented by social platforms, may lead to the emergence\nof self-defined subpopulations, each managed by a surrounding ecosystem of healthcare\nproviders augmented with automated recommendation and monitoring systems.\n\nThese developments have the potential to radically transform healthcare LeighAnne Olsen, Dara Aisner, and J.\n\nMichael McGinnis, eds., “Institute of Medicine\n(US) Roundtable on Evidence-Based Medicine,” The Learning Healthcare System: Workshop Summary., nlm.nih.gov/books/NBK53500/ .\n\nKatherine E.\n\nHenry , David N.\n\nHager, Peter J.\n\nPronovost, and Suchi Saria, “ A Targeted Realtime Early Warning Score (TREWScore) for Septic Shock,” Science Translational Medicine , (299),\n299ra122.AI-based applications\ncould improve health\noutcomes and quality of\nlife for millions of people\nin the coming years—but\nonly if they gain the trust\nof doctors, nurses, and\npatients.\n\n27delivery as medical procedures and lifetime clinical records for hundreds of millions\nof individuals become available.\n\nSimilarly , the automated capture of personal\nenvironmental data from wearable devices will expand personalized medicine.\n\nThese\nactivities are becoming more commercially viable as vendors discover ways to engage\nlarge populations (e.g.\n\nShareCare)63 and then to create population-scale data that can\nbe mined to produce individualized analytics and recommendations.\n\nUnfortunately , the FDA has been slow to approve innovative diagnostic software,\nand there are many remaining barriers to rapid innovation.\n\nHIPAA (Health Insurance\nPortability and Accountability Act) requirements for protecting patient privacy create\nlegal barriers to the flow of patient data to applications that could utilize AI technologies.\n\nUnanticipated negative effects of approved drugs could show up routinely , sooner, and\nmore rigorously than they do today , but mobile apps that analyze drug interactions\nmay be blocked from pulling the necessary information from patient records.\n\nMore\ngenerally , AI research and innovation in healthcare are hampered by the lack of\nwidely accepted methods and standards for privacy protection.\n\nThe FDA has been\nslow to approve innovative software, in part due to an unclear understanding of the\ncost/benefit tradeoffs of these systems.\n\nIf regulators (principally the FDA) recognize\nthat effective post-marketing reporting is a dependable hedge against some safety risks,\nfaster initial approval of new treatments and interventions may become possible.\n\nAutomated image interpretation has also been a promising subject of study for\ndecades.\n\nProgress on interpreting large archives of weakly-labeled images, such as\nlarge photo archives scraped from the web, has been explosive.\n\nAt first blush, it is\nsurprising that there has not been a similar revolution in interpretation of medical\nimages.\n\nMost medical imaging modalities (CT , MR, ultrasound) are inherently digital,\nthe images are all archived, and there are large, established companies with internal\nR&D (e.g.\n\nSiemens, Philips, GE) devoted to imaging.\n\nBut several barriers have limited progress to date.\n\nMost hospital image archives\nhave only gone digital over the past decade.\n\nMore importantly , the problem in\nmedicine is not to recognize what is in the image (is this a liver or a kidney?), but\nrather to make a fine-grained judgement about it (does the slightly darker smudge\nin the liver suggest a potentially cancerous tumor?).\n\nStrict regulations govern these\nhigh-stakes judgements.\n\nEven with state-of-the-art technologies, a radiologist will still\nlikely have to look at the images, so the value proposition is not yet compelling.\n\nAlso,\nhealthcare regulations preclude easy federation of data across institutions.\n\nThus, only\nvery large organizations of integrated care, such as Kaiser Permanente, are able to\nattack these problems.\n\nStill, automated/augmented image interpretation has started to gain momentum.\n\nThe next fifteen years will probably not bring fully automated radiology , but initial forays\ninto image “triage” or second level checking will likely improve the speed and costeffectiveness of medical imaging.\n\nWhen coupled with electronic patient record systems,\nlarge-scale machine learning techniques could be applied to medical image data.\n\nFor\nexample, multiple major healthcare systems have archives of millions of patient scans,\neach of which has an associated radiological report, and most have an associated\npatient record.",
      "section_path": [
        "INTELLIGENCE?"
      ],
      "metadata": {
        "chunk_index": 11,
        "char_count": 6215,
        "token_estimate": 1204,
        "word_count": 896,
        "has_header": true,
        "header_text": "INTELLIGENCE?",
        "header_level": 2,
        "parent_sections": [],
        "contains_list": false,
        "contains_numbered_list": false,
        "contains_quote": false,
        "contains_code": false,
        "embedding_ready": true,
        "total_chunks_in_doc": 22,
        "prev_chunk_id": "artificial_intelligence_chunk_010",
        "next_chunk_id": "artificial_intelligence_chunk_012"
      }
    },
    {
      "vector_id": 12,
      "chunk_id": "artificial_intelligence_chunk_012",
      "content": "## INTELLIGENCE?\n\nFor\nexample, multiple major healthcare systems have archives of millions of patient scans,\neach of which has an associated radiological report, and most have an associated\npatient record.\n\nAlready , papers are appearing in the literature showing that deep neural\nnetworks can be trained to produce basic radiological findings, with high reliability ,\nby training from this data.64 Sharecare, Jianhua Yao, Daniel Mollura, and Ronald M.\n\nSummers, “Deep Convolutional Neural Networks for\nComputer-aided Detection: CNN Architectures, Dataset Characteristics and Transfer Learning,”\nIEEE Transactions on Medical Imaging 35, no.: 1285–1298.A small group of companies\ncontrol the EHR market,\nand user interfaces\nare widely considered\nsubstandard, including\nannoying pop-ups that\nphysicians routinely\ndismiss.\n\n28Healthcare robotics\nFifteen years ago, healthcare robotics was largely science fiction.\n\nOne company\ncalled Robodoc,65 a spin-out from IBM, developed robotic systems for orthopedic\nsurgeries, such as hip and knee replacements.\n\nThe technology worked, but the\ncompany struggled commercially , and was ultimately shut down and acquired for\nits technology .66 More recently , though, the research and practical use of surgical\nrobotics has exploded.\n\nIn Intuitive Surgical67 introduced the da Vinci system, a novel technology\ninitially marketed to support minimally invasive heart bypass surgery , and then gained\nsubstantial market traction for treatment of prostate cancer and merged with its\nonly major competition, Computer Motion, in 2003.\n\nThe da Vinci, now in its fourth\ngeneration, provides 3D visualization (as opposed to 2D monocular laparoscopy) and\nwristed instruments in an ergonomic platform.\n\nIt is considered the standard of care\nin multiple laparoscopic procedures, and used in nearly three quarters of a million\nprocedures a year,68 providing not only a physical platform, but also a new data\nplatform for studying the process of surgery .\n\nThe da Vinci anticipates a day when much greater insight into how medical\nprofessionals carry out the process of providing interventional medical care will\nbe possible.\n\nThe presence of the da Vinci in day-to-day operation has also opened\nthe doors to new types of innovation—from new instrumentation to image fusion\nto novel biomarkers—creating its own innovation ecosystem.\n\nThe success of the\nplatform has inspired potential competitors in robotic surgery , most notably the\nAlphabet spin-off Verb, in collaboration with J&J/Ethicon.69 There are likely to be\nmany more, each exploring a unique niche or space and building out an ecosystem of\nsensing, data analytics, augmentation, and automation.\n\nIntelligent automation in hospital operations has been less successful.\n\nThe story\nis not unlike surgical robotics.\n\nTwenty years ago, one company , HelpMate, created\na robot for hospital deliveries,70 such as meals and medical records, but ultimately\nwent bankrupt.\n\nMore recently , Aethon71 introduced TUG Robots for basic deliveries,\nbut few hospitals have invested in this technology to date.\n\nHowever, robotics in\nother service industries such as hotels and warehouses, including Amazon Robotics\n(formerly Kiva), are demonstrating that these technologies are practical and cost\neffective in at least some large-scale settings, and may ultimately spur additional\ninnovation in health care.\n\nLooking ahead, many tasks that appear in healthcare will be amenable to\naugmentation, but will not be fully automated.\n\nFor example, robots may be able to\ndeliver goods to the right room in a hospital, but then require a person to pick them\nup and place them in their final location.\n\nWalking a patient down the corridor may ROBODOC, Procedure Volumes,” Forbes , January 22, 2016, sites/greatspeculations/2016/01/22/intuitive-surgical-maintains-its-growth-momentum-withstrong-growth-in-procedure-volumes/#22ae6b0939a1 .\n\nEvan Ackerman, “Google and Johnson & Johnson Conjugate to Create Verb Surgical,\nPromise Fancy Medical Robots,” IEEE Spectrum , December 17, 2015,\nverb-surgical-medical-robots .\n\nJohn M.\n\nEvans and Bala Krishnamurthy , “HelpMate®, the trackless robotic courier: A\nperspective on the development of a commercial autonomous mobile robot,” Lecture Notes in Control\nand Information Sciences , June 18,, 182–210,\nis not to recognize what is\nin the image—is this a liver\nor a kidney?—but rather\nto make a fine-grained\njudgement about it.\n\nStrict\nregulations govern these\nhigh-stakes judgements.\n\n29be relatively simple once a patient is standing in a walker (though will certainly not\nbe trivial for patients recovering from surgery and/or elderly patients, especially in\ncorridors crowded with equipment and other people).\n\nDriving a needle to place a\nsuture is relatively straightforward once the needle is correctly placed.72 This implies\nthat many future systems will involve intimate interaction between people and\nmachines and require technologies that facilitate collaboration between them.\n\nThe growth of automation will enable new insights into healthcare processes.\n\nHistorically , robotics has not been a strongly data-driven or data-oriented science.\n\nThis is changing as (semi)automation infiltrates healthcare.\n\nAs the new surgical,\ndelivery , and patient care platforms come online, the beginnings of quantification\nand predictive analytics are being built on top of data coming from these platforms.73\nThis data will be used to assess quality of performance, identify deficiencies, errors,\nor potential optimizations, and will be used as feedback to improve performance.\n\nIn\nshort, these platforms will facilitate making the connection between what is done, and\nthe outcome achieved, making true “closed-loop” medicine a real possibility .",
      "section_path": [
        "INTELLIGENCE?"
      ],
      "metadata": {
        "chunk_index": 12,
        "char_count": 5744,
        "token_estimate": 1200,
        "word_count": 830,
        "has_header": true,
        "header_text": "INTELLIGENCE?",
        "header_level": 2,
        "parent_sections": [],
        "contains_list": false,
        "contains_numbered_list": false,
        "contains_quote": false,
        "contains_code": false,
        "embedding_ready": true,
        "total_chunks_in_doc": 22,
        "prev_chunk_id": "artificial_intelligence_chunk_011",
        "next_chunk_id": "artificial_intelligence_chunk_013"
      }
    },
    {
      "vector_id": 13,
      "chunk_id": "artificial_intelligence_chunk_013",
      "content": "## INTELLIGENCE?\n\nIn\nshort, these platforms will facilitate making the connection between what is done, and\nthe outcome achieved, making true “closed-loop” medicine a real possibility .\n\nMobile health\nTo date, evidence-driven analytics on healthcare have relied on traditional healthcare\ndata—mainly the electronic medical records discussed above.\n\nIn the clinical setting,\nthere are hopeful trends towards bringing new data to bear.\n\nFor example, TeleLanguage enables a human clinician to conduct language therapy sessions with\nmultiple patients simultaneously with the aid of an AI agent trained by the clinician.\n\nAnd Lifegraph, which extracts behavioral patterns and creates alerts from data\npassively collected from a patient’s smartphone, has been adopted by psychiatrists in\nIsrael to detect early signs of distressful behavior in patients.\n\nLooking ahead, driven by the mobile computing revolution, the astonishing growth\nof “biometrics in the wild”—and the explosion of platforms and applications that use\nthem—is a hopeful and unanticipated trend.\n\nThousands of mobile apps now offer\ninformation, introduce behavior modification, or identify groups of “people like me.”\nThis, combined with the emerging trend of more specialized motion tracking devices,\nsuch as Fitbit, and the emerging (inter)connectedness between the home environment\nand health-monitoring devices, has created a vibrant new sector of innovation.\n\nBy combining social and healthcare data, some healthcare apps can perform data\nmining, learning, and prediction from captured data, though their predictions are\nrelatively rudimentary .\n\nThe convergence of data and functionality across applications\nwill likely spur new and even obvious products, such as an exercise app that not only\nproposes a schedule for exercise but also suggests the best time to do it, and provides\ncoaching to stick to that schedule.\n\nAzad Shademan, Ryan S.\n\nDecker, Justin D.\n\nOpfermann, Simon Leonard, Axel Krieger, and\nPeter CW Kim, “Supervised Autonomous Robotic Soft Tissue Surgery ,” Science Translational Medicine\n8, no.: 337ra64–337ra64.\n\nCarolyn Chen, Lee White, Timothy Kowalewski, Rajesh Aggarwal, Chris Lintott, Bryan\nComstock, Katie Kuksenok, Cecilia Aragon, Daniel Holst, and Thomas Lendvay , “Crowd-Sourced\nAssessment of Technical Skills: a novel method to evaluate surgical performance.” Journal of Surgical\nResearch 187, no.: 65–71.Specialized motion\ntracking devices...\n\nand\nthe emerging (inter)\nconnectedness between\nthe home environment and\nhealth-monitoring devices\nhave created a vibrant new\nsector of innovation.\n\n30Elder care\nOver the next fifteen years the number of elderly in the United States will grow\nby over 50%.74 The National Bureau of Labor Statistics projects that home health\naides will grow 38% over the next ten years.\n\nDespite the broad opportunities in this\ndomain—basic social support, interaction and communication devices, home health\nmonitoring, a variety of simple in-home physical aids such as walkers, and light meal\npreparation—little has happened over the past fifteen years.\n\nBut the coming generational\nshift will accompany a change in technology acceptance among the elderly .\n\nCurrently ,\nsomeone who is seventy was born in and may have first experienced some form\nof personalized IT in middle age or later, while a fifty-year-old today is far more\ntechnology-friendly and savvy .\n\nAs a result, there will be a growing interest and market\nfor already available and maturing technologies to support physical, emotional, social,\nand mental health.\n\nHere are a few likely examples by category:\nLife quality and independence\n- Automated transportation will support continued independence and expanded\nsocial horizons.\n\n- Sharing of information will help families remain engaged with one another at a\ndistance, and predictive analytics may be used to “nudge” family groups toward\npositive behaviors, such as reminders to “call home.”\n- Smart devices in the home will help with daily living activities when needed,\nsuch as cooking and, if robot manipulation capabilities improve sufficiently ,\ndressing and toileting.\n\nHealth and wellness\n- Mobile applications that monitor movement and activities, coupled with social\nplatforms, will be able to make recommendations to maintain mental and\nphysical health.\n\n- In-home health monitoring and health information access will be able to detect\nchanges in mood or behavior and alert caregivers.\n\n- Personalized health management will help mitigate the complexities associated\nwith multiple co-morbid conditions and/or treatment interactions.\n\nTreatments and devices\n- Better hearing aids and visual assistive devices will mitigate the effects of\nhearing and vision loss, improving safety and social connection.\n\n- Personalized rehabilitation and in-home therapy will reduce the need for\nhospital or care facility stays.\n\n- Physical assistive devices (intelligent walkers, wheel chairs, and exoskeletons) will\nextend the range of activities of an infirm individual.\n\nThe Study Panel expects an explosion of low-cost sensing technologies that can\nprovide substantial capabilities to the elderly in their homes.\n\nIn principle, social\nagents with a physical presence and simple physical capabilities (e.g.\n\na mobile robot\nwith basic communication capabilities) could provide a platform for new innovations.\n\nHowever, doing so will require integration across multiple areas of AI—Natural\nLanguage Processing, reasoning, learning, perception, and robotics—to create\na system that is useful and usable by the elderly .\n\nThese innovations will also introduce questions regarding privacy within various\ncircles, including friends, family , and care-givers, and create new challenges to\naccommodate an evermore active and engaged population far past retirement.\n\nJennifer M.\n\nOrtman, Victoria A.",
      "section_path": [
        "INTELLIGENCE?"
      ],
      "metadata": {
        "chunk_index": 13,
        "char_count": 5828,
        "token_estimate": 1164,
        "word_count": 845,
        "has_header": true,
        "header_text": "INTELLIGENCE?",
        "header_level": 2,
        "parent_sections": [],
        "contains_list": true,
        "contains_numbered_list": false,
        "contains_quote": false,
        "contains_code": false,
        "embedding_ready": true,
        "total_chunks_in_doc": 22,
        "prev_chunk_id": "artificial_intelligence_chunk_012",
        "next_chunk_id": "artificial_intelligence_chunk_014"
      }
    },
    {
      "vector_id": 14,
      "chunk_id": "artificial_intelligence_chunk_014",
      "content": "## INTELLIGENCE?\n\nOrtman, Victoria A.\n\nVelkoff, and Howard Hogan, “ An Aging Nation: The\nOlder Population in the United States: Population Estimates and Projections,” Current Population\nReports , U.S Census Bureau, prod/2014pubs/p25-1140.pdf .Better hearing aids and\nvisual assistive devices\nwill mitigate the effects\nof hearing and vision\nloss, improving safety\nand social connection.\n\nPersonalized rehabilitation\nand in-home therapy\nwill reduce the need for\nhospital stays.\n\n31EDUCATION\nThe past fifteen years have seen considerable AI advances in education.\n\nApplications\nare in wide use by educators and learners today , with some variation between K-12\nand university settings.\n\nThough quality education will always require active engagement\nby human teachers, AI promises to enhance education at all levels, especially by\nproviding personalization at scale.\n\nSimilar to healthcare, resolving how to best\nintegrate human interaction and face-to-face learning with promising AI technologies\nremains a key challenge.\n\nRobots have long been popular educational devices, starting with the early\nLego Mindstorms kits developed with the MIT Media Lab in the 1980s.\n\nIntelligent\nTutoring Systems (ITS) for science, math, language, and other disciplines match\nstudents with interactive machine tutors.\n\nNatural Language Processing, especially when\ncombined with machine learning and crowdsourcing, has boosted online learning\nand enabled teachers to multiply the size of their classrooms while simultaneously\naddressing individual students’ learning needs and styles.\n\nThe data sets from large\nonline learning systems have fueled rapid growth in learning analytics.\n\nStill, schools and universities have been slow in adopting AI technologies primarily\ndue to lack of funds and lack of solid evidence that they help students achieve\nlearning objectives.\n\nOver the next fifteen years in a typical North American city , the\nuse of intelligent tutors and other AI technologies to assist teachers in the classroom\nand in the home is likely to expand significantly , as will learning based on virtual\nreality applications.\n\nBut computer-based learning systems are not likely to fully\nreplace human teaching in schools.\n\nTeaching robots\nToday , more sophisticated and versatile kits for use in K-12 schools are available\nfrom a number of companies that create robots with new sensing technologies\nprogrammable in a variety of languages.\n\nOzobot is a robot that teaches children\nto code and reason deductively while configuring it to dance or play based on\ncolor-coded patterns.75 Cubelets help teach children logical thinking through\nassembling robot blocks to think, act, or sense, depending upon the function of the\ndifferent blocks.76 Wonder Workshop’s Dash and Dot span a range of programming\ncapabilities.\n\nChildren eight years old and older can create simple actions using a\nvisual programming language, Blockly , or build iOS and Android applications using\nC or Java.77 PLEO rb is a robot pet that helps children learn biology by teaching\nthe robot to react to different aspects of the environment.78 However, while fun and\nengaging for some, in order for such kits to become widespread, there will need to be\ncompelling evidence that they improve students’ academic performance.\n\nIntelligent Tutoring Systems (ITS) and online learning\nITS have been developed from research laboratory projects such as Why-2 Atlas,\nwhich supported human-machine dialogue to solve physics problems early in the\nera.79 The rapid migration of ITS from laboratory experimental stages to real use is Ozobot, cubelets .\n\n“Meet Dash,” Wonder Workshop, dash.\n\n“Pleo rb,” Innvo Labs, lifeform.php .\n\nKurt VanLehn, Pamela W .\n\nJordan, Carolyn P .\n\nRosé, Dumisizwe Bhembe, Michael Böttner,\nAndy Gaydos, Maxim Makatchev, Umarani Pappuswamy , Michael Ringenberg, Antonio Roque,\nStephanie Siler, and Ramesh Srivastava, “The Architecture of Why2-Atlas: A Coach for Qualitative Though quality education\nwill always require active\nengagement by human\nteachers, AI promises to\nenhance education at\nall levels, especially by\nproviding personalization\nat scale.\n\n32surprising and welcome.\n\nDownloadable software and online systems such as Carnegie\nSpeech or Duolingo provide foreign language training using Automatic Speech\nRecognition (ASR) and NLP techniques to recognize language errors and help users\ncorrect them.80 Tutoring systems such as the Carnegie Cognitive Tutor81 have been\nused in US high schools to help students learn mathematics.\n\nOther ITS have been\ndeveloped for training in geography , circuits, medical diagnosis, computer literacy\nand programming, genetics, and chemistry .\n\nCognitive tutors use software to mimic\nthe role of a good human tutor by , for example, providing hints when a student gets\nstuck on a math problem.\n\nBased on the hint requested and the answer provided, the\ntutor offers context specific feedback.\n\nApplications are growing in higher education.\n\nAn ITS called SHERLOCK82 is\nbeginning to be used to teach Air Force technicians to diagnose electrical systems\nproblems in aircraft.\n\nAnd the University of Southern California’s Information\nSciences Institute has developed more advanced avatar-based training modules to\ntrain military personnel being sent to international posts in appropriate behavior\nwhen dealing with people from different cultural backgrounds.\n\nNew algorithms for\npersonalized tutoring, such as Bayesian Knowledge Tracing, enable individualized\nmastery learning and problem sequencing.83\nMost surprising has been the explosion of the Massive Open Online Courses\n(MOOCs) and other models of online education at all levels—including the use\nof tools like Wikipedia and Khan Academy as well as sophisticated learning\nmanagement systems that build in synchronous as well as asynchronous education\nand adaptive learning tools.",
      "section_path": [
        "INTELLIGENCE?"
      ],
      "metadata": {
        "chunk_index": 14,
        "char_count": 5844,
        "token_estimate": 1183,
        "word_count": 859,
        "has_header": true,
        "header_text": "INTELLIGENCE?",
        "header_level": 2,
        "parent_sections": [],
        "contains_list": false,
        "contains_numbered_list": false,
        "contains_quote": false,
        "contains_code": false,
        "embedding_ready": true,
        "total_chunks_in_doc": 22,
        "prev_chunk_id": "artificial_intelligence_chunk_013",
        "next_chunk_id": "artificial_intelligence_chunk_015"
      }
    },
    {
      "vector_id": 15,
      "chunk_id": "artificial_intelligence_chunk_015",
      "content": "## INTELLIGENCE?\n\nNew algorithms for\npersonalized tutoring, such as Bayesian Knowledge Tracing, enable individualized\nmastery learning and problem sequencing.83\nMost surprising has been the explosion of the Massive Open Online Courses\n(MOOCs) and other models of online education at all levels—including the use\nof tools like Wikipedia and Khan Academy as well as sophisticated learning\nmanagement systems that build in synchronous as well as asynchronous education\nand adaptive learning tools.\n\nSince the late 1990s, companies such as the Educational\nTesting Service and Pearson have been developing automatic NLP assessment tools to\nco-grade essays in standardized testing.84 Many of the MOOCs which have become\nso popular, including those created by EdX, Coursera, and Udacity , are making use\nof NLP , machine learning, and crowdsourcing techniques for grading short-answer\nand essay questions as well as programming assignments.85 Online education systems\nthat support graduate-level professional education and lifelong learning are also\nexpanding rapidly .\n\nThese systems have great promise because the need for face-to-face interaction is less important for working professionals and career changers.\n\nWhile not\nthe leaders in AI-supported systems and applications, they will become early adopters\nas the technologies are tested and validated.\n\nIt can be argued that AI is the secret sauce that has enabled instructors, particularly\nin higher education, to multiply the size of their classrooms by a few orders of\nmagnitude—class sizes of a few tens of thousands are not uncommon.\n\nIn order to\ncontinually test large classes of students, automated generation of the questions is\nPhysics Essay Writing,” Intelligent Tutoring Systems: Proceedings of the 6th International Conference , (Springer\nBerlin Heidelberg, 2002), 158–167.\n\nVanLehn et al, “The Architecture of Why2-Atlas.” “Resources and Support,” Carnegie Learning, carnegielearning.com/resources-support/ .\n\nAlan Lesgold, Suzanne Lajoie, Marilyn Bunzo, and Gary Eggan, “SHERLOCK: A Coached\nPractice Environment for an Electronics Troubleshooting Job,” in J.\n\nH.\n\nLarkin and R.\n\nW .\n\nChabay ,\neds., Computer-Assisted Instruction and Intelligent Tutoring Systems: Shared Goals and Complementary Approaches Michael V .\n\nYudelson, Kenneth R.\n\nKoedinger, and Geoffrey J.\n\nGordon, “ Individualized\nBayesian Knowledge Tracing Models,” Artificial Intelligence in Education , (Springer Berlin Heidelberg,\n2013), 171–180.\n\nJill Burstein, Karen Kukich, Susanne Wolff, Chi Lu, Martin Chodorow, Lisa Braden-Harder,\nand Mary Dee Harris, “ Automated Scoring Using a Hybrid Feature Identification Technique ” in\nProceedings of the Annual Meeting of the Association of Computational Linguistics , Montreal, Canada, August\n1998, udacity .com/ , all is the secret sauce that\nhas enabled instructors,\nparticularly in higher\neducation, to multiply the\nsize of their classrooms\nby a few orders of\nmagnitude—class sizes of\na few tens of thousands\nare not uncommon.\n\n33also possible, such as those designed to assess vocabulary ,86 wh (who/what/when/\nwhere/why) questions,87 and multiple choice questions,88 using electronic resources\nsuch as WordNet, Wikipedia, and online ontologies.\n\nWith the explosion of online\ncourses, these techniques are sure to be eagerly adopted for use in online education.\n\nAlthough the long term impact of these systems will have on the educational system\nremains unclear, the AI community has learned a great deal in a very short time.\n\nLearning analytics\nData sets being collected from massive scale online learning systems, ranging from\nMOOCs to Khan Academy , as well as smaller scale online programs, have fueled\nthe rapid growth of the field of learning analytics.\n\nOnline courses are not only good\nfor widespread delivery , but are natural vehicles for data collection and experimental\ninstrumentation that will contribute to scientific findings and improving the quality\nof learning at scale.\n\nOrganizations such as the Society for Learning Analytics\nResearch (SOLAR), and the rise of conferences including the Learning Analytics and\nKnowledge Conference89 and the Learning at Scale Conference (L@S)90 reflect this\ntrend.\n\nThis community applies deep learning, natural language processing, and other\nAI techniques to analysis of student engagement, behavior, and outcomes.\n\nCurrent projects seek to model common student misconceptions, predict\nwhich students are at risk of failure, and provide real-time student feedback that is\ntightly integrated with learning outcomes.\n\nRecent work has also been devoted to\nunderstanding the cognitive processes involved in comprehension, writing, knowledge\nacquisition, and memory , and to applying that understanding to educational practice\nby developing and testing educational technologies.\n\nChallenges and opportunities\nOne might have expected more and more sophisticated use of AI technologies in\nschools, colleges, and universities by now.\n\nMuch of its absence can be explained\nby the lack of financial resources of these institutions as well as the lack of data\nestablishing the technologies’ effectiveness.\n\nThese problems are being addressed,\nalbeit slowly , by private foundations and by numerous programs to train primarily\nsecondary school teachers in summer programs.\n\nAs in other areas of AI, excessive\nhype and promises about the capabilities of MOOCs have meant that expectations\nfrequently exceed the reality .\n\nThe experiences of certain institutions, such as San Jose\nState University’s experiment with Udacity ,91 have led to more sober assessment of\nthe potential of the new educational technologies.\n\nJonathan C.\n\nBrown, Gwen A.\n\nFrishkoff , and Maxine Eskenazi, “ Automatic Question\nGeneration for Vocabulary Assessment,” Proceedings of Human Language Technology Conference and\nConference on Empirical Methods in Natural Language Processing (HLT/EMNLP) , Vancouver, October\n2005,, 819–826.",
      "section_path": [
        "INTELLIGENCE?"
      ],
      "metadata": {
        "chunk_index": 15,
        "char_count": 5928,
        "token_estimate": 1205,
        "word_count": 856,
        "has_header": true,
        "header_text": "INTELLIGENCE?",
        "header_level": 2,
        "parent_sections": [],
        "contains_list": false,
        "contains_numbered_list": false,
        "contains_quote": false,
        "contains_code": false,
        "embedding_ready": true,
        "total_chunks_in_doc": 22,
        "prev_chunk_id": "artificial_intelligence_chunk_014",
        "next_chunk_id": "artificial_intelligence_chunk_016"
      }
    },
    {
      "vector_id": 16,
      "chunk_id": "artificial_intelligence_chunk_016",
      "content": "## INTELLIGENCE?\n\nFrishkoff , and Maxine Eskenazi, “ Automatic Question\nGeneration for Vocabulary Assessment,” Proceedings of Human Language Technology Conference and\nConference on Empirical Methods in Natural Language Processing (HLT/EMNLP) , Vancouver, October\n2005,, 819–826.\n\nMichael Heilman, “ Automatic Factual Question Generation from Text,” PhD thesis CMULTI-11-004,, edu/~ark/mheilman/questions/papers/heilman-question-generation-dissertation.pdf .\n\nTahani Alsubait, Bijan Parsia, and Uli Sattler, “Generating Multiple Choice Questions from\nOntologies: How Far Can We Go?,” in eds.\n\nP .\n\nLambrix, E.\n\nHyvönen.\n\nE.\n\nBlomqvist, V .\n\nPresutti, G.\n\nQi, U.\n\nSattler, Y .\n\nDing, and C.\n\nGhidini, Knowledge Engineering and Knowledge Management: EKAW Satellite Events, VISUAL, EKM1, and ARCOE-Logic Linköping, Sweden, November 24–28, Revised\nSelected Papers,, 66–79.\n\nThe 6th International Learning Analytics & Knowledge Conference, .\n\nThird Annual ACM Conference on Learning at Scale,\nlas2016/ .\n\nRy Rivard, “Udacity Project on ‘Pause’,” Inside Higher Ed , July 18, 2013, accessed August 1,\n2016,\nsan-jose-state-pauses-work-udacity .The current absence of\nsophisticated use of AI\ntechnologies in schools,\ncolleges, and universities\nmay be explained by\nthe lack of financial\nresources as well as the\nlack of data establishing\nthe technologies’\neffectiveness.\n\n34In the next fifteen years, it is likely that human teachers will be assisted by AI\ntechnologies with better human interaction, both in the classroom and in the home.\n\nThe Study Panel expects that more general and more sophisticated virtual reality\nscenarios in which students can immerse themselves in subjects from all disciplines\nwill be developed.\n\nSome steps in this direction are being taken now by increasing\ncollaborations between AI researchers and researchers in the humanities and social\nsciences, exemplified by Stanford’s Galileo Correspondence Project92 and Columbia’s\nMaking and Knowing Project.93 These interdisciplinary efforts create interactive\nexperiences with historical documents and the use of Virtual Reality (VR) to explore\ninteractive archeological sites.94 VR techniques are already being used in the natural\nsciences such as biology , anatomy , geology and astronomy to allow students to interact\nwith environments and objects that are difficult to engage with in the real world.\n\nThe\nrecreation of past worlds and fictional worlds will become just as popular for studies\nof arts and other sciences.\n\nAI techniques will increasingly blur the line between formal, classroom education\nand self-paced, individual learning.\n\nAdaptive learning systems, for example, are going\nto become a core part of the teaching process in higher education because of the\npressures to contain cost while serving a larger number of students and moving students\nthrough school more quickly .\n\nWhile formal education will not disappear, the Study\nPanel believes that MOOCs and other forms of online education will become part of\nlearning at all levels, from K-12 through university , in a blended classroom experience.\n\nThis development will facilitate more customizable approaches to learning, in which\nstudents can learn at their own pace using educational techniques that work best for\nthem.\n\nOnline education systems will learn as the students learn, supporting rapid\nadvances in our understanding of the learning process.\n\nLearning analytics, in turn, will\naccelerate the development of tools for personalized education.\n\nThe current transition from hard copy books to digital and audio media and texts\nis likely to become prevalent in education as well.\n\nDigital reading devices will also\nbecome much ‘smarter’, providing students with easy access to additional information\nabout subject matter as they study .\n\nMachine Translation (MT) technology will\nalso make it easier to translate educational material into different languages with a\nfair degree of accuracy , just as it currently translates technical manuals.\n\nTextbook\ntranslation services that currently depend only upon human translators will\nincreasingly incorporate automatic methods to improve the speed and affordability of\ntheir services for school systems.\n\nOnline learning systems will also expand the opportunity for adults and working\nprofessionals to enhance their knowledge and skills (or to retool and learn a new field)\nin a world where these fields are evolving rapidly .\n\nThis will include the expansion\nof fully online professional degrees as well as professional certifications based on\nonline coursework.\n\nBroader societal consequences\nIn countries where education is difficult for the broad population to obtain, online\nresources may have a positive effect if the population has the tools to access them.\n\nThe development of online educational resources should make it easier for\nfoundations that support international educational programs to provide quality Stanford University: Galileo Correspondence Project, stanford.edu .\n\nThe Making and Knowing Project: Reconstructing the 16th Century Workshop of BNF MS.\n\nFR.\n\nat Columbia University , 31, 2015, archaeology-to-life/.While formal education\nwill not disappear, the\nStudy Panel believes that\nMOOCs and other forms\nof online education will\nbecome part of learning\nat all levels, from K-12\nthrough university, in\na blended classroom\nexperience.\n\n35education by providing tools and relatively simple amounts of training in their use.\n\nFor example, large numbers of educational apps, many of them free, are being\ndeveloped for the iPad.\n\nOn the negative side, there is already a major trend among\nstudents to restrict their social contacts to electronic ones and to spend large amounts\nof time without social contact, interacting with online programs.",
      "section_path": [
        "INTELLIGENCE?"
      ],
      "metadata": {
        "chunk_index": 16,
        "char_count": 5753,
        "token_estimate": 1192,
        "word_count": 836,
        "has_header": true,
        "header_text": "INTELLIGENCE?",
        "header_level": 2,
        "parent_sections": [],
        "contains_list": false,
        "contains_numbered_list": false,
        "contains_quote": false,
        "contains_code": false,
        "embedding_ready": true,
        "total_chunks_in_doc": 22,
        "prev_chunk_id": "artificial_intelligence_chunk_015",
        "next_chunk_id": "artificial_intelligence_chunk_017"
      }
    },
    {
      "vector_id": 17,
      "chunk_id": "artificial_intelligence_chunk_017",
      "content": "## INTELLIGENCE?\n\nOn the negative side, there is already a major trend among\nstudents to restrict their social contacts to electronic ones and to spend large amounts\nof time without social contact, interacting with online programs.\n\nIf education also\noccurs more and more online, what effect will the lack of regular, face-to-face contact\nwith peers have on students’ social development?\n\nCertain technologies have even\nbeen shown to create neurological side effects.95 On the other hand, autistic children\nhave benefited from interactions with AI systems already .96\nLOW-RESOURCE COMMUNITIES\nMany opportunities exist for AI to improve conditions for people in low-resource\ncommunities in a typical North American city—and, indeed, in some cases it\nalready has.\n\nUnderstanding these direct AI contributions may also inform potential\ncontributions in the poorest parts of the developing world.\n\nThere has not been a\nsignificant focus on these populations in AI gatherings, and, traditionally , AI funders\nhave underinvested in research lacking commercial application.\n\nWith targeted incentives\nand funding priorities, AI technologies could help address the needs of low-resource\ncommunities.\n\nBudding efforts are promising.\n\nCounteracting fears that AI may contribute\nto joblessness and other societal problems, AI may provide mitigations and solutions,\nparticularly if implemented in ways that build trust in them by the affected communities.\n\nMachine learning, data mining approaches\nUnder the banner of “data science for social good,” AI has been used to create\npredictive models to help government agencies more effectively use their limited\nbudgets to address problems such as lead poisoning,97 a major public health concern\nthat has been in the news due to ongoing events in Flint, Michigan.\n\nChildren may\nbe tested for elevated lead levels, but that unfortunately means the problem is only\ndetected after they have already been poisoned.\n\nMany efforts are underway to use\npredictive models to assist government agencies in prioritizing children at\nrisk, including those who may not yet have been exposed.98 Similarly , the Illinois\nDepartment of Human Services (IDHS) uses predictive models to identify pregnant\nwomen at risk for adverse birth outcomes in order to maximize the impact of\nprenatal care.\n\nThe City of Cincinnati uses them to proactively identify and deploy\ninspectors to properties at risk of code violations.\n\nScheduling, planning\nTask assignment scheduling and planning techniques have been applied by many\ndifferent groups to distribute food before it spoils from those who may have excess,\nsuch as restaurants, to food banks, community centers and individuals.99 Scientist have studied, for example, the way reliance on GPS may lead to changes in the\nhippocampus.\n\nKim Tingley , “The Secrets of the Wave Pilots,” The New York Times , March 17, 2016,\npilots.html.\n\nJudith Newman, “To Siri, With Love: How One Boy With Autism Became BFF With Apple’s\nSiri,” The New York Times , October 17, 2014, com/2014/10/19/fashion/how-apples-siri-became-one-autistic-boys-bff.html.\n\nEric Potash, Joe Brew, Alexander Loewi, Subhabrata Majumdar, Andrew Reece, Joe Walsh,\nEric Rozier, Emile Jorgensen, Raed Mansour, and Rayid Ghani, “Predictive Modeling for Public\nHealth: Preventing Childhood Lead Poisoning,” Proceedings of the 21th ACM SIGKDD International\nConference on Knowledge Discovery and Data Mining (New York: Association for Computing Machinery ,\n2015), 2039–2047.\n\nData Science for Social Good, University of Chicago, .\n\nSenay Solak, Christina Scherrer, and Ahmed Ghoniem, “The Stop-and-Drop Problem in\nNonprofit Food Distribution Networks,” Annals of Operations Research , no.: With targeted incentives\nand funding priorities, AI\ntechnologies could help\naddress the needs of lowresource communities.\n\nBudding efforts are\npromising.\n\n36Reasoning with social networks and influence maximization\nSocial networks can be harnessed to create earlier, less-costly interventions involving\nlarge populations.\n\nFor example, AI might be able to assist in spreading healthrelated information.\n\nIn Los Angeles, there are more than 5,000 homeless youth (ages\nthirteen-twenty-four).\n\nIndividual interventions are difficult and expensive, and the\nyouths’ mistrust of authority dictates that key messages are best spread through peer\nleaders.\n\nAI programs might be able to leverage homeless youth social networks to\nstrategically select peer leaders to spread health-related information, such as how to\navoid spread of HIV .\n\nThe dynamic, uncertain nature of these networks does pose\nchallenges for AI research.100 Care must also be taken to prevent AI systems from\nreproducing discriminatory behavior, such as machine learning that identifies people\nthrough illegal racial indicators, or through highly-correlated surrogate factors, such\nas zip codes.\n\nBut if deployed with great care, greater reliance on AI may well result\nin a reduction in discrimination overall, since AI programs are inherently more easily\naudited than humans.\n\nPUBLIC SAFETY AND SECURITY\nCities already have begun to deploy AI technologies for public safety and security .\n\nBy 2030, the typical North American city will rely heavily upon them.\n\nThese include\ncameras for surveillance that can detect anomalies pointing to a possible crime,\ndrones, and predictive policing applications.\n\nAs with most issues, there are benefits\nand risks.\n\nGaining public trust is crucial.\n\nWhile there are legitimate concerns that\npolicing that incorporates AI may become overbearing or pervasive in some contexts,\nthe opposite is also possible.\n\nAI may enable policing to become more targeted and\nused only when needed.\n\nAnd assuming careful deployment, AI may also help remove\nsome of the bias inherent in human decision-making .",
      "section_path": [
        "INTELLIGENCE?"
      ],
      "metadata": {
        "chunk_index": 17,
        "char_count": 5793,
        "token_estimate": 1196,
        "word_count": 852,
        "has_header": true,
        "header_text": "INTELLIGENCE?",
        "header_level": 2,
        "parent_sections": [],
        "contains_list": false,
        "contains_numbered_list": false,
        "contains_quote": false,
        "contains_code": false,
        "embedding_ready": true,
        "total_chunks_in_doc": 22,
        "prev_chunk_id": "artificial_intelligence_chunk_016",
        "next_chunk_id": "artificial_intelligence_chunk_018"
      }
    },
    {
      "vector_id": 18,
      "chunk_id": "artificial_intelligence_chunk_018",
      "content": "## INTELLIGENCE?\n\nAnd assuming careful deployment, AI may also help remove\nsome of the bias inherent in human decision-making .\n\nOne of the more successful uses of AI analytics is in detecting white collar\ncrime, such as credit card fraud.101 Cybersecurity (including spam) is a widely shared\nconcern, and machine learning is making an impact.\n\nAI tools may also prove useful\nin helping police manage crime scenes or search and rescue events by helping\ncommanders prioritize tasks and allocate resources, though these tools are not yet\nready for automating such activities.\n\nImprovements in machine learning in general,\nand transfer learning in particular—for speeding up learning in new scenarios based\non similarities with past scenarios—may facilitate such systems.\n\nThe cameras deployed almost everywhere in the world today tend to be more\nuseful for helping solve crimes than preventing them.102 This is due to the low\nquality of event identification from videos and the lack of manpower to look at\nmassive video streams.\n\nAs AI for this domain improves, it will better assist crime\nprevention and prosecution through greater accuracy of event classification and\nefficient automatic processing of video to detect anomalies—including, potentially ,\n407–426.\n\nJordan Pearson, “ Artificial Intelligence Could Help Reduce HIV Among Homeless Youths,”\nTeamcore, University of Southern California, February 4.\n\n2015, teamcore.usc.edu/news/motherboard_news_ai_could_help_reduce_HIV .pdf.\n\n“RSA Adaptive Authentication,” RSA, products-services/fraud-prevention/adaptive-authentication .\n\nTakeshi Arikuma and Yasunori Mochizuki, “Intelligent multimedia surveillance system for\nsafer cities” APSIPA Transactions on Signal and Information Processing: 1–8.\n\n“Big Op-Ed: Shifting Opinions On Surveillance Cameras,”, Talk of the Nation , NPR, April 22,\n2013, opinions-on-surveillance-cameras .One of the more successful\nuses of AI analytics is in\ndetecting white collar\ncrime, such as credit\ncard fraud.\n\nCybersecurity\n(including spam) is a\nwidely shared concern,\nand machine learning is\nmaking an impact.\n\n37evidence of police malpractice.\n\nThese improvements could lead to even more\nwidespread surveillance.\n\nSome cities have already added drones for surveillance\npurposes, and police use of drones to maintain security of ports, airports, coastal\nareas, waterways, industrial facilities is likely to increase, raising concerns about\nprivacy , safety , and other issues.\n\nThe New York Police Department’s CompStat was the first tool pointing toward\npredictive policing,104 and many police departments now use it.105 Machine learning\nsignificantly enhances the ability to predict where and when crimes are more likely\nto happen and who may commit them.\n\nAs dramatized in the movie Minority Report ,\npredictive policing tools raise the specter of innocent people being unjustifiably\ntargeted.\n\nBut well-deployed AI prediction tools have the potential to actually remove\nor reduce human bias, rather than reinforcing it, and research and resources should\nbe directed toward ensuring this effect.\n\nAI techniques can be used to develop intelligent simulations for training lawenforcement personnel to collaborate.\n\nWhile international criminal organizations and\nterrorists from different countries are colluding, police forces from different countries\nstill face difficulty in joining forces to fight them.\n\nTraining international groups of law\nenforcement personnel to work as teams is very challenging.\n\nThe European Union,\nthrough the Horizon program, currently supports such attempts in projects such\nas LawTrain.106 The next step will be to move from simulation to actual investigations\nby providing tools that support such collaborations.\n\nTools do exist for scanning Twitter and other feeds to look for certain types\nof events and how they may impact security .\n\nFor example, AI can help in social\nnetwork analysis to prevent those at risk from being radicalized by ISIS or other\nviolent groups.\n\nLaw enforcement agencies are increasingly interested in trying to\ndetect plans for disruptive events from social media, and also to monitor activity at\nlarge gatherings of people to analyze security .\n\nThere is significant work on crowd\nsimulations to determine how crowds can be controlled.\n\nAt the same time, legitimate\nconcerns have been raised about the potential for law enforcement agencies to\noverreach and use such tools to violate people’s privacy .\n\nThe US Transportation Security Administration (TSA), Coast Guard, and the\nmany other security agencies that currently rely on AI will likely increase their\nreliance to enable significant efficiency and efficacy improvements.107 AI techniques—\nvision, speech analysis, and gait analysis— can aid interviewers, interrogators, and\nsecurity guards in detecting possible deception and criminal behavior.\n\nFor example,\nthe TSA currently has an ambitious project to redo airport security nationwide.108\nCalled DARMS, the system is designed to improve efficiency and efficacy of airport\nsecurity by relying on personal information to tailor security based on a person’s risk\ncategorization and the flights being taken.\n\nThe future vision for this project is a tunnel\nthat checks people’s security while they walk through it.\n\nOnce again, developers of\nthis technology should be careful to avoid building in bias (e.g.\n\nabout a person’s risk\nlevel category) through use of datasets that reflect prior bias.109 Walter L.\n\nPerry , Brian McInnis, Carter C.\n\nPrice, Susan Smith, and John S.\n\nHollywood, “The\nRole of Crime Forecasting in Law Enforcement Operations,” Rand Corporation Report “CompStat,” Wikipedia , last modified July 28, 2016, en.wikipedia.org/wiki/CompStat .\n\nLAW-TRAIN, Cambridge University Press, 2011).",
      "section_path": [
        "INTELLIGENCE?"
      ],
      "metadata": {
        "chunk_index": 18,
        "char_count": 5760,
        "token_estimate": 1155,
        "word_count": 834,
        "has_header": true,
        "header_text": "INTELLIGENCE?",
        "header_level": 2,
        "parent_sections": [],
        "contains_list": false,
        "contains_numbered_list": false,
        "contains_quote": false,
        "contains_code": false,
        "embedding_ready": true,
        "total_chunks_in_doc": 22,
        "prev_chunk_id": "artificial_intelligence_chunk_017",
        "next_chunk_id": "artificial_intelligence_chunk_019"
      }
    },
    {
      "vector_id": 19,
      "chunk_id": "artificial_intelligence_chunk_019",
      "content": "## INTELLIGENCE?\n\nLAW-TRAIN, Cambridge University Press, 2011).\n\nPeter Neffenger, “TSA ’s Budget—A Commitment to Security (Part I),” Department\nof Homeland Security , March 1, 2016, testimony/2016/03/01/hearing-fy17-budget-request-transportation-security-administration .\n\nCrawford, “ AI’s White Guy Problem.”As dramatized in the\nmovie Minority Report ,\npredictive policing tools\nraise the specter of\ninnocent people being\nunjustifiably targeted.\n\nBut\nwell-deployed AI prediction\ntools have the potential to\nactually remove or reduce\nhuman bias.\n\n38EMPLOYMENT AND WORKPLACE\nWhile AI technologies are likely to have a profound future impact on employment\nand workplace trends in a typical North American city , it is difficult to accurately\nassess current impacts, positive or negative.\n\nIn the past fifteen years, employment\nhas shifted due to a major recession and increasing globalization, particularly with\nChina’s introduction to the world economy , as well as enormous changes in non-AI\ndigital technology .\n\nSince the 1990s, the US has experienced continued growth in\nproductivity and GDP , but median income has stagnated and the employment to\npopulation ratio has fallen.\n\nThere are clear examples of industries in which digital technologies have had\nprofound impacts, good and bad, and other sectors in which automation will likely\nmake major changes in the near future.\n\nMany of these changes have been driven\nstrongly by “routine” digital technologies, including enterprise resource planning,\nnetworking, information processing, and search.\n\nUnderstanding these changes should\nprovide insights into how AI will affect future labor demand, including the shift in\nskill demands.\n\nTo date, digital technologies have been affecting workers more in the\nskilled middle, such as travel agents, rather than the very lowest-skilled or highest\nskilled work.110 On the other hand, the spectrum of tasks that digital systems can\ndo is evolving as AI systems improve, which is likely to gradually increase the scope\nof what is considered routine.\n\nAI is also creeping into high end of the spectrum,\nincluding professional services not historically performed by machines.\n\nTo be successful, AI innovations will need to overcome understandable human\nfears of being marginalized.\n\nAI will likely replace tasks rather than jobs in the near\nterm, and will also create new kinds of jobs.\n\nBut the new jobs that will emerge are\nharder to imagine in advance than the existing jobs that will likely be lost.\n\nChanges\nin employment usually happen gradually , often without a sharp transition, a trend\nlikely to continue as AI slowly moves into the workplace.\n\nA spectrum of effects will\nemerge, ranging from small amounts of replacement or augmentation to complete\nreplacement.\n\nFor example, although most of a lawyer’s job is not yet automated,111\nAI applied to legal information extraction and topic modeling has automated parts of\nfirst-year lawyers’ jobs.112 In the not too distant future, a diverse array of job-holders,\nfrom radiologists to truck drivers to gardeners, may be affected.\n\nAI may also influence the size and location of the workforce.\n\nMany organizations\nand institutions are large because they perform functions that can be scaled only by\nadding human labor, either “horizontally” across geographical areas or “vertically”\nin management hierarchies.\n\nAs AI takes over many functions, scalability no longer\nimplies large organizations.\n\nMany have noted the small number of employees of\nsome high profile internet companies, but not of others.\n\nThere may be a natural scale\nof human enterprise, perhaps where the CEO can know everyone in the company .\n\nThrough the creation of efficiently outsourced labor markets enabled by AI,\nenterprises may tend towards that natural size.\n\nAI will also create jobs, especially in some sectors, by making certain tasks more\nimportant, and create new categories of employment by making new modes of\ninteraction possible.\n\nSophisticated information systems can be used to create new Jeremy Ashkenas and Alicia Parlapiano, “How the Recession Reshaped the Economy , in Charts,” The New York Times , June 6, 2014, interactive/2014/06/05/upshot/how-the-recession-reshaped-the-economy-in-255-charts.html .\n\nR Dana Remus and Frank S.\n\nLevy , “Can Robots Be Lawyers?\n\nComputers, Lawyers, and the\nPractice of Law,” Social Science Research Network , last modified February 12, 2016, accessed August 1,\n2016, John Markoff, “ Armies of Expensive Lawyers, Replaced by Cheaper Software,” The New\nYork Times , March 4, 2011, science/05legal.html .AI will likely replace tasks\nrather than jobs in the\nnear term, and will also\ncreate new kinds of jobs.\n\nBut the new jobs that\nwill emerge are harder to\nimagine in advance than\nthe existing jobs that will\nlikely be lost.\n\n39markets, which often have the effect of lowering barriers to entry and increasing\nparticipation—from app stores to AirBnB to taskrabbit.\n\nA vibrant research\ncommunity within AI studies further ways of creating new markets and making\nexisting ones operate more efficiently .\n\nWhile work has intrinsic value, most people work to be able to purchase goods and\nservices they value.\n\nBecause AI systems perform work that previously required human\nlabor, they have the effect of lowering the cost of many goods and services, effectively\nmaking everyone richer.\n\nBut as exemplified in current political debates, job loss is\nmore salient to people—especially those directly affected—than diffuse economic\ngains, and AI unfortunately is often framed as a threat to jobs rather than a boon to\nliving standards.",
      "section_path": [
        "INTELLIGENCE?"
      ],
      "metadata": {
        "chunk_index": 19,
        "char_count": 5599,
        "token_estimate": 1187,
        "word_count": 850,
        "has_header": true,
        "header_text": "INTELLIGENCE?",
        "header_level": 2,
        "parent_sections": [],
        "contains_list": false,
        "contains_numbered_list": false,
        "contains_quote": false,
        "contains_code": false,
        "embedding_ready": true,
        "total_chunks_in_doc": 22,
        "prev_chunk_id": "artificial_intelligence_chunk_018",
        "next_chunk_id": "artificial_intelligence_chunk_020"
      }
    },
    {
      "vector_id": 20,
      "chunk_id": "artificial_intelligence_chunk_020",
      "content": "## INTELLIGENCE?\n\nBut as exemplified in current political debates, job loss is\nmore salient to people—especially those directly affected—than diffuse economic\ngains, and AI unfortunately is often framed as a threat to jobs rather than a boon to\nliving standards.\n\nThere is even fear in some quarters that advances in AI will be so rapid as\nto replace all human jobs—including those that are largely cognitive or involve\njudgment—within a single generation.\n\nThis sudden scenario is highly unlikely , but\nAI will gradually invade almost all employment sectors, requiring a shift away from\nhuman labor that computers are able to take over.\n\nThe economic effects of AI on cognitive human jobs will be analogous to\nthe effects of automation and robotics on humans in manufacturing jobs.\n\nMany\nmiddle-aged workers have lost well-paying factory jobs and the socio-economic status\nin family and society that traditionally went with such jobs.\n\nAn even larger fraction\nof the total workforce may , in the long run, lose well-paying “cognitive” jobs.\n\nAs labor\nbecomes a less important factor in production as compared to owning intellectual\ncapital, a majority of citizens may find the value of their labor insufficient to pay for\na socially acceptable standard of living.\n\nThese changes will require a political, rather\nthan a purely economic, response concerning what kind of social safety nets should\nbe in place to protect people from large, structural shifts in the economy .\n\nAbsent\nmitigating policies, the beneficiaries of these shifts may be a small group at the\nupper stratum of the society .113\nIn the short run, education, re-training, and inventing new goods and services may\nmitigate these effects.\n\nLonger term, the current social safety net may need to evolve into\nbetter social services for everyone, such as healthcare and education, or a guaranteed\nbasic income.\n\nIndeed, countries such as Switzerland and Finland have actively considered\nsuch measures.\n\nAI may be thought of as a radically different mechanism of wealth\ncreation in which everyone should be entitled to a portion of the world’s AI-produced\ntreasure.114 It is not too soon for social debate on how the economic fruits of\nAI-technologies should be shared.\n\nAs children in traditional societies support their\naging parents, perhaps our artificially intelligent “children” should support us, the\n“parents” of their intelligence.\n\nFor example, Brynjolfsson and McAfee, Second Machine Age , have two chapters of devoted to\nthis (Erik Brynjolfsson and Andrew McAfee, The Second Machine Age: Work, Progress, and Prosperity in a\nTime of Brilliant Technologies ,) and Brynjolfsson,\nMcAfee, and Spence describe policy responses for the combination of globalization and digital\ntechnology (Erik Brynjolfsson, Andrew McAfee, and Michael Spence, Foreign Affairs , July/August\n2014, 2014-06-04/new-world-order ).\n\nGDP does not do a good job of measuring the value of many digital goods.\n\nWhen society\ncan’t manage what isn’t measured, bad policy decisions result.\n\nOne alternative is to look at\nconsumer surplus, not just dollar flows.\n\nAs AI is embodied in more goods, this issue becomes more\nsalient.\n\nIt may look like GDP goes down but people have better well-being through access to these\ndigital goods.\n\nSee Erik Brynjolfsson and Adam Saunders, “What the GDP Gets Wrong (Why\nManagers Should Care),” Sloan Management Review , vol.\n\n51, no.: 95–96.As labor becomes a\nless important factor in\nproduction as compared\nto owning intellectual\ncapital, a majority of\ncitizens may find the value\nof their labor insufficient\nto pay for a socially\nacceptable standard of\nliving.\n\n40ENTERTAINMENT\nWith the explosive growth of the internet over the past fifteen years, few can imagine\ntheir daily lives without it.\n\nPowered by AI, the internet has established user-generated\ncontent as a viable source of information and entertainment.\n\nSocial networks such\nas Facebook are now pervasive, and they function as personalized channels of\nsocial interaction and entertainment—sometimes to the detriment of interpersonal\ninteraction.\n\nApps such as WhatsApp and Snapchat enable smart-phone users to\nremain constantly “in touch” with peers and share sources of entertainment and\ninformation.\n\nIn on-line communities such as Second Life and role-playing games such\nas World of Warcraft, people imagine an alternative existence in a virtual world.115\nSpecialized devices, such as Amazon’s Kindle have also redefined the essentials of\nlong-cherished pastimes.\n\nBooks can now be browsed and procured with a few swipes\nof the finger, stored by the thousands in a pocket-sized device, and read in much the\nsame way as a handheld paperback.\n\nTrusted platforms now exist for sharing and browsing blogs, videos, photos, and\ntopical discussions, in addition to a variety of other user-generated information.\n\nTo\noperate at the scale of the internet, these platforms must rely on techniques that are\nbeing actively developed in natural language processing, information retrieval, image\nprocessing, crowdsourcing, and machine learning.\n\nAlgorithms such as collaborative\nfiltering have been developed, for example, to recommend relevant movies, songs, or\narticles based on the user’s demographic details and browsing history .116\nTraditional sources of entertainment have also embraced AI to keep pace with the\ntimes.\n\nAs exemplified in the book and movie Moneyball , professional sport is now subjected\nto intensive quantitative analysis.117 Beyond aggregate performance statistics, on-field\nsignals can be monitored using sophisticated sensors and cameras.",
      "section_path": [
        "INTELLIGENCE?"
      ],
      "metadata": {
        "chunk_index": 20,
        "char_count": 5593,
        "token_estimate": 1148,
        "word_count": 855,
        "has_header": true,
        "header_text": "INTELLIGENCE?",
        "header_level": 2,
        "parent_sections": [],
        "contains_list": false,
        "contains_numbered_list": false,
        "contains_quote": false,
        "contains_code": false,
        "embedding_ready": true,
        "total_chunks_in_doc": 22,
        "prev_chunk_id": "artificial_intelligence_chunk_019",
        "next_chunk_id": "artificial_intelligence_chunk_021"
      }
    },
    {
      "vector_id": 21,
      "chunk_id": "artificial_intelligence_chunk_021",
      "content": "## INTELLIGENCE?\n\nAs exemplified in the book and movie Moneyball , professional sport is now subjected\nto intensive quantitative analysis.117 Beyond aggregate performance statistics, on-field\nsignals can be monitored using sophisticated sensors and cameras.\n\nSoftware has been\ncreated for composing music118 and recognizing soundtracks.119 Techniques from computer\nvision and NLP have been used in creating stage performances.120 Even the lay user can\nexercise his or her creativity on platforms such as WordsEye, which automatically\ngenerates 3D scenes from natural language text.121 AI has also come to the aid of\nhistorical research in the arts, and is used extensively in stylometry and, more recently ,\nin the analysis of paintings.122\nThe enthusiasm with which humans have responded to AI-driven entertainment\nhas been surprising and led to concerns that it reduces interpersonal interaction\namong human beings.\n\nFew predicted that people would spend hours on end\ninteracting with a display .\n\nChildren often appear to be genuinely happier playing\nat home on their devices rather than outside with their friends.\n\nAI will increasingly\nenable entertainment that is more interactive, personalized, and engaging.\n\nResearch\nshould be directed toward understanding how to leverage these attributes for\nindividuals’ and society’s benefit.\n\nSecond Life, Entertainment, Inc, Algorithms for Collaborative Filtering,” Proceedings of the 14th Conference on Uncertainty in Artificial\nIntelligence, Company , Inc., 2003): ).\n\nMuseScore, en.wikipedia.org/wiki/Stylometry ; will increasingly enable\nentertainment that is more\ninteractive, personalized,\nand engaging.\n\nResearch\nshould be directed toward\nunderstanding how to\nleverage these attributes\nfor individuals’ and\nsociety’s benefit.\n\n41Imagining the Future\nThe success of any form of entertainment is ultimately determined by the individuals\nand social groups that are its subjects.\n\nThe modes of entertainment that people find\nappealing are diverse and change over time.\n\nIt is therefore hard to predict the forms\nentertainment will take in the next fifteen years precisely .\n\nNevertheless, current trends\nsuggest at least a few features that the future entertainment landscape is likely to contain.\n\nTo date, the information revolution has mostly unfolded in software.\n\nHowever,\nwith the growing availability of cheaper sensors and devices, greater innovation in the\nhardware used in entertainment systems is expected.\n\nVirtual reality and haptics could\nenter our living rooms—personalized companion robots are already being developed.123\nWith the accompanying improvements in Automatic Speech Recognition, the Study\nPanel expects that interaction with robots and other entertainment systems will become\ndialogue-based, perhaps constrained at the start, but progressively more human-like.\n\nEqually , the interacting systems are predicted to develop new characteristics such as\nemotion, empathy , and adaptation to environmental rhythms such as time of day .124\nToday , an amateur with a video camera and readily-available software tools can\nmake a relatively good movie.\n\nIn the future, more sophisticated tools and apps will\nbecome available to make it even easier to produce high-quality content, for example,\nto compose music or to choreograph dance using an avatar.\n\nThe creation and\ndissemination of entertainment will benefit from the progress of technologies such as\nASR, dubbing, and Machine Translation, which will enable content to be customized\nto different audiences inexpensively .\n\nThis democratization and proliferation of AIcreated media makes it difficult to predict how humans’ taste for entertainment, which\nare already fluid, will evolve.\n\nWith content increasingly delivered digitally , and large amounts of data being\nlogged about consumers’ preferences and usage characteristics, media powerhouses\nwill be able to micro-analyze and micro-serve content to increasingly specialized\nsegments of the population—down to the individual.125 Conceivably the stage is set\nfor the emergence of media conglomerates acting as “Big Brothers” who are able to\ncontrol the ideas and online experiences to which specific individuals are exposed.\n\nIt remains to be seen whether broader society will develop measures to prevent their\nemergence.\n\nThis topic, along with others pertaining to AI-related policy , is treated in\nmore detail in the next section.\n\nEmoters, 995–1051.More sophisticated tools\nand apps will become\navailable to make it\neven easier to produce\nhigh-quality content, for\nexample, to compose\nmusic or to choreograph\ndance using an avatar.",
      "section_path": [
        "INTELLIGENCE?"
      ],
      "metadata": {
        "chunk_index": 21,
        "char_count": 4612,
        "token_estimate": 884,
        "word_count": 665,
        "has_header": true,
        "header_text": "INTELLIGENCE?",
        "header_level": 2,
        "parent_sections": [],
        "contains_list": false,
        "contains_numbered_list": false,
        "contains_quote": false,
        "contains_code": false,
        "embedding_ready": true,
        "total_chunks_in_doc": 22,
        "prev_chunk_id": "artificial_intelligence_chunk_020",
        "next_chunk_id": null
      }
    }
  ]
}